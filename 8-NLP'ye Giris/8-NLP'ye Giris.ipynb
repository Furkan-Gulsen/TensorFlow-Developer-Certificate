{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-FLLJVK6JTX"
   },
   "source": [
    "# NLP'ye Giriş\n",
    "\n",
    "Doğal dil işlemenin (NLP) temel amacı, doğal dilden bilgi elde etmektir. Doğal dil geniş bir terimdir ancak aşağıdakilerden herhangi birini kapsadığını düşünebilirsiniz:\n",
    "\n",
    "- Metin (bir e-postada, blog gönderisinde, kitapta, Tweette bulunanlar gibi)\n",
    "- Konuşma (bir doktorla yaptığınız konuşma, telefonuna verdiğiniz sesli komutlar)\n",
    "\n",
    "Metin ve konuşma şemsiyesi altında yapmak isteyebileceğiniz birçok farklı şey var. Bir e-posta uygulaması oluşturuyorsanız, spam olup olmadıklarını (sınıflandırma) görmek için gelen e-postaları taramak isteyebilirsiniz.\n",
    "\n",
    "Müşteri geri bildirim şikayetlerini analiz etmeye çalışıyorsanız, bunların işletmenizin hangi bölümü için olduğunu keşfetmek isteyebilirsiniz.\n",
    "\n",
    "> 🔑 Not: Bu tür verilerin her ikisine de genellikle diziler denir (bir cümle, bir sözcük dizisidir). Bu nedenle, NLP problemlerinde karşılaşacağınız yaygın bir terime **seq2seq** denir, başka bir deyişle, bir dizideki bilgiyi başka bir dizi oluşturmak için bulmak (örneğin, bir konuşma komutunu metin tabanlı adımlar dizisine dönüştürmek).\n",
    "\n",
    "TensorFlow'da NLP ile pratik yapmak için daha önce kullandığımız adımları bu sefer metin verileriyle uygulayacağız:\n",
    "\n",
    "```\n",
    "Metin -> sayılara dönüştürün -> bir model oluşturun -> modeli kalıpları bulmak için eğitin -> kalıpları kullanın (tahminlerde bulunun)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2ukU0W_7zSa"
   },
   "source": [
    "## İçerik: \n",
    "\n",
    "- Bir metin veri kümesini indirme\n",
    "- Metin verilerini görselleştirme\n",
    "- Tokenization kullanarak metni sayılara dönüştürme\n",
    "- Belirtilmiş metnimizi bir gömmeye dönüştürmek\n",
    "- Bir metin veri kümesini modelleme\n",
    "  - Temel ile başlama (TF-IDF)\n",
    "  - Birkaç derin öğrenme metin modeli oluşturma\n",
    "    - Yoğun, LSTM, GRU, Conv1D, Aktarım öğrenimi\n",
    "- Her bir modelimizin performansını karşılaştırma\n",
    "- Modellerimizi bir toplulukta birleştirmek\n",
    "- Eğitilmiş bir modeli kaydetme ve yükleme\n",
    "- En yanlış tahminleri bulunma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-JL4f327KqF"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OM1lBpB7NDm"
   },
   "source": [
    "Eğitime başlamadan önce gerekli fonksiyonları oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q1gveJ497PdU"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4w6Fqd3N7QNt"
   },
   "outputs": [],
   "source": [
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JJuNMaxq7SQ8"
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S60P5oxP7TPX"
   },
   "outputs": [],
   "source": [
    "def compare_historys(original_history, new_history, initial_epochs=5):\n",
    "\n",
    "    acc = original_history.history[\"accuracy\"]\n",
    "    loss = original_history.history[\"loss\"]\n",
    "\n",
    "    val_acc = original_history.history[\"val_accuracy\"]\n",
    "    val_loss = original_history.history[\"val_loss\"]\n",
    "\n",
    "    total_acc = acc + new_history.history[\"accuracy\"]\n",
    "    total_loss = loss + new_history.history[\"loss\"]\n",
    "\n",
    "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
    "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(total_acc, label='Training Accuracy')\n",
    "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
    "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "              plt.ylim(), label='Start Fine Tuning') \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(total_loss, label='Training Loss')\n",
    "    plt.plot(total_val_loss, label='Validation Loss')\n",
    "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "              plt.ylim(), label='Start Fine Tuning')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a__qLI8u7aVE"
   },
   "outputs": [],
   "source": [
    "def unzip_data(filename):\n",
    "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
    "  zip_ref.extractall()\n",
    "  zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gc_St8WjjQMq"
   },
   "outputs": [],
   "source": [
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE0FMtz49ICq"
   },
   "source": [
    "## Veri Kümesini İndirme\n",
    "\n",
    "Bir metin veri kümesi indirerek başlayalım. [Real or Not](https://www.kaggle.com/c/nlp-getting-started/data)'u kullanacağız. Doğal afetler hakkında metin tabanlı Tweetler içeren Kaggle sitesinde bulunan veri seti.\n",
    "\n",
    "**Gerçek Tweetler** aslında felaketlerle ilgilidir, örneğin:\n",
    "\n",
    "```\n",
    "Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano\n",
    "```\n",
    "\n",
    "**Gerçek Olmayan Tweetler**, felaketlerle ilgili olmayan Tweetlerdir (her konuda olabilir), örneğin:\n",
    "\n",
    "```\n",
    "'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjxU31BZ8OTF",
    "outputId": "76d1d733-e2e2-415b-cbf7-fe34791f41b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-01 15:36:28--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.128, 142.250.141.128, 142.251.2.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 607343 (593K) [application/zip]\n",
      "Saving to: ‘nlp_getting_started.zip’\n",
      "\n",
      "\r",
      "nlp_getting_started   0%[                    ]       0  --.-KB/s               \r",
      "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2021-08-01 15:36:28 (146 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download data (same as from Kaggle)\n",
    "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
    "\n",
    "# Unzip data\n",
    "unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6Iegcid962f"
   },
   "source": [
    "`nlp_getting_started.zip` dosyasında 3 farklı csv belgesi vardır: Bunlar: \n",
    "\n",
    "- **sample_submission.csv** \n",
    "Modelinizin tahminlerini içeren Kaggle yarışmasına göndereceğiniz dosyanın bir örneği.\n",
    "- **train.csv**\n",
    "Gerçek ve gerçek olmayan felaket Tweetlerinin eğitim örnekleri.\n",
    "- **test.csv**\n",
    "Gerçek ve gerçek olmayan felaket Tweet örneklerinin test edilmesi için örnekler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcrQuPvq-hkW"
   },
   "source": [
    "<img src=\"https://boostlabs.com/wp-content/uploads/2019/09/10-types-of-data-visualization-1.jpg\" />\n",
    "\n",
    "## Bir Metin Veri Kümesini Görselleştirme\n",
    "\n",
    "Çalışmak için yeni bir veri kümesi edindikten sonra, önce ne yapmalısınız? Keşfetmek mi? Kontrol et? Doğrula? Onunla bir olmak mı? Hepsi doğru :)\n",
    "\n",
    "Sloganı hatırlayın: görselleştirin, görselleştirin, görselleştirin.\n",
    "\n",
    "Şu anda metin veri örneklerimiz .csv dosyaları biçimindedir. Onları görsel hale getirmenin kolay bir yolu için onları pandas DataFrame'e çevirelim.\n",
    "\n",
    "> 📖 Okuma: Birçok farklı formatta metin veri setleriyle karşılaşabilirsiniz. CSV dosyalarının (üzerinde çalıştığımız şey) yanı sıra, muhtemelen .txt dosyaları ve .json dosyalarıyla da karşılaşacaksınız. Bu tür dosyalarla çalışmak için RealPython'un aşağıdaki iki makalesini okumanızı tavsiye ederim:\n",
    "\n",
    "- [Python'da Dosyalar Nasıl Okunur ve Yazılır](https://realpython.com/read-write-files-python/)\n",
    "- [Python'da JSON Verileriyle Çalışmak](https://realpython.com/python-json/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "F4QSJaAe94g9",
    "outputId": "8b8ef9af-0710-4d1c-dc2a-f41e8aa1b567"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword  ...                                               text target\n",
       "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
       "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
       "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
       "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
       "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .csv dosyalarını pandas DataFrame'lerine dönüştürün\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juU1aELy-7PU"
   },
   "source": [
    "İndirdiğimiz eğitim verileri muhtemelen zaten karıştırılmıştır. Ama emin olmak için tekrar karıştıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "zR6jP-WM-1oh",
    "outputId": "5ac4c9fd-fe13-486a-d986-de63ea5b1819"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ... target\n",
       "2644  3796  ...      1\n",
       "2227  3185  ...      0\n",
       "5448  7769  ...      1\n",
       "132    191  ...      0\n",
       "6845  9810  ...      0\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) \n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfWGT5r8Rly0"
   },
   "source": [
    "Eğitim verilerinin nasıl bir `\"target\"` sütunu olduğuna dikkat edin.\n",
    "\n",
    "`\"target\"` sütununun değerini tahmin etmek için eğitim veri kümesinin `\"text\"` sütununda kalıpları (örneğin farklı kelime kombinasyonları) bulmak için kod yazacağız. Test veri kümesinin bir `\"target\"` sütunu yok.\n",
    "\n",
    "```\n",
    "Inputs (text column) -> Machine Learning Algorithm -> Outputs (target column)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4WPHIixL-8_z",
    "outputId": "c979f71f-c751-4863-dd69-c39d3b30eecc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test verilerinin bir hedefi yok (tahmin etmeye çalıştığımız şey bu)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfrjiOyER5CG"
   },
   "source": [
    "Her hedeften kaç tane örneğimiz olduğunu kontrol edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aK8LDvpuRyz_",
    "outputId": "b7626101-0e83-483e-99ec-13100f54a287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Her sınıftan kaç örnek var?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYaZ_y_IR87F"
   },
   "source": [
    "İki sınıf değeri olduğundan, `binary_classification` problemiyle uğraşacağız gibi duruyor. Veri setimizi incelediğimizde dengeli bir dağılım görüyoruz. %60 olumsuz, %40 olumlu sınıf içeriyor.\n",
    "\n",
    "- 1: gerçek bir felaket twet'i\n",
    "- 0: gerçek olmayan bir felaket twet'i\n",
    "\n",
    "Peki elimizde ki toplam örnek sayısı kaç?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvJ80UEbR6q7",
    "outputId": "83404bfa-2b18-4c28-a211-947e0cf5c96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhXnbXHgWFZ_"
   },
   "source": [
    "Pekala, yeterli miktarda eğitim ve test verisine sahibiz gibi görünüyor. Görselleştirme zamanı, hadi rastgele metin örneklerini görselleştirmek için bazı kodlar yazalım.\n",
    "\n",
    "> **🤔 Soru:** Rastgele örnekleri neden görselleştirelim? Örnekleri sırayla görselleştirebilirsiniz, ancak bu yalnızca belirli bir veri alt kümesini görmenize neden olabilir. Üzerinde çalıştığınız farklı veri türleri hakkında bir fikir edinmek için önemli miktarda (100+) rastgele örneği görselleştirmek daha iyidir. Makine öğreniminde rastgeleliğin gücünü asla hafife almayın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xz6qDbVHS5fW",
    "outputId": "3fc58e74-e513-4617-bb71-6508d3a4b7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "catastrophic-fallen-angel: reveillertm: macabrelolita: I was supposed to write Û÷amino acidsÛª and I nearly... http://t.co/dIoBzGHFju\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "'if you can't summon the flames directly from hell store bought is fine'-me \n",
      "mom-*dies*\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Back in 02 to 03 would never said that 50 would have ended ja like obliteration\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "How can we help save a beautiful town in Ontario from destruction by a power plant developer?\n",
      "http://t.co/hlD5xLYwBn\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "that exploded &amp; brought about the\n",
      "beginning of universe matches what's\n",
      "mentioned in the versethe heaven and Earth\n",
      "(thus the universe)\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) \n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DREMCSSSWYz7"
   },
   "source": [
    "## Verileri Eğitim ve Doğrulama Kümelerine Ayırın\n",
    "\n",
    "Test setinde etiket olmadığından ve eğitilmiş modellerimizi değerlendirmek için bir yola ihtiyacımız olduğundan, eğitim verilerinden bazılarını ayıracağız ve bir doğrulama seti oluşturacağız.\n",
    "\n",
    "Modelimiz eğitildiğinde (Tweet örneklerindeki kalıpları denediğinde), yalnızca eğitim kümesindeki verileri görür ve doğrulama kümesini kullanarak görünmeyen veriler üzerinde nasıl performans gösterdiğini görebiliriz.\n",
    "\n",
    "Pandas Series veri türlerinden bölmelerimizi daha sonra kullanım kolaylığı için string listelerine (metin için) ve ints listelerine (etiketler için) dönüştüreceğiz.\n",
    "\n",
    "Eğitim veri setimizi bölmek ve bir doğrulama veri seti oluşturmak için Scikit-Learn'in `train_test_split()` yöntemini kullanacağız ve eğitim örneklerinin %10'unu doğrulama setine ayıracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RI4_-V18WNFd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oDyTk1wWpI5",
    "outputId": "c8cb8f1c-6cef-4016-92a1-9b076f2a5272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DgSyLzdWw6B",
    "outputId": "64e4859b-13ff-43bc-fafe-f05fd2e59ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXlSlAmwW2Wr"
   },
   "source": [
    "## Metni Sayılara dönüştürme\n",
    "\n",
    "Tweetler ve etiketler içeren bir eğitim setimiz ve bir doğrulama setimiz var. Etiketlerimiz sayısal (0 ve 1) biçimindedir, ancak Tweetlerimiz dize biçimindedir.\n",
    "\n",
    "> 🤔 Soru: Metin verilerimizle bir makine öğrenmesi algoritması kullanabilmemiz için sizce ne yapmamız gerekiyor?\n",
    "\n",
    "\"Sayıya çevir\" gibi bir cevap verdiyseniz, haklısınız. Bir makine öğrenimi algoritması, girdilerinin sayısal biçimde olmasını gerektirir.\n",
    "\n",
    "NLP'de metni sayılara dönüştürmek için iki ana kavram vardır:\n",
    "\n",
    "- **Tokenization**<br>\n",
    "Kelimeden veya karakterden veya alt kelimeden sayısal bir değere düz bir eşleme. Üç ana tokenizasyon seviyesi vardır:\n",
    "  1. Kelime düzeyinde simgeleştirmeyi \"I love TensorFlow\" cümlesiyle kullanmak, \"I\"nin 0, \"love\"  1 ve \"TensorFlow\"un 2 olmasına neden olabilir. Bu durumda, bir dizideki her sözcük tek bir simge olarak kabul edilir.\n",
    "  2. A-Z harflerini 1-26 değerlerine dönüştürmek gibi karakter düzeyinde simgeleştirme. Bu durumda, bir dizideki her karakter tek bir simge olarak kabul edilir.\n",
    "  3. Alt sözcük belirleme, sözcük düzeyinde ve karakter düzeyinde simgeleştirme arasındadır. Tek tek kelimeleri daha küçük parçalara ayırmayı ve ardından bu daha küçük parçaları sayılara dönüştürmeyi içerir. Örneğin, \"my favorite food is pineapple pizza\", \"my, favor, rite, fo, oo, od, is, pin, ine, app, le, piz, za\" olabilir. Bunu yaptıktan sonra, bu alt kelimeler daha sonra sayısal bir değere eşlenir. Bu durumda, her kelime birden fazla belirteç olarak kabul edilebilir.\n",
    "\n",
    "- **Embedding**<br>\n",
    "Embed, öğrenilebilen doğal dilin bir temsilidir. Temsil, bir özellik vektörü şeklinde gelir. Örneğin, \"dance\" kelimesi 5 boyutlu vektör [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112] ile temsil edilebilir. Burada not etmek önemlidir, özellik vektörünün boyutu ayarlanabilir. Embed kullanmanın iki yolu vardır:\n",
    "  1. Kendi embed işleminizi oluşturun - Metniniz sayılara dönüştürüldüğünde (embed için gereklidir), onları bir embed  katmanına (tf.keras.layers.Embedding gibi) koyabilirsiniz ve model eğitimi sırasında bir embed gösterimi öğrenilecektir.\n",
    "  2. Önceden öğrenilmiş bir yerleştirmeyi yeniden kullanın - Çevrimiçi olarak önceden eğitilmiş birçok yerleştirme mevcuttur. Bu önceden eğitilmiş yerleştirmeler genellikle büyük metin kütlelerinde (tüm Wikipedia'da olduğu gibi) öğrenilmiştir ve bu nedenle doğal dilin iyi bir temel temsiline sahiptir. Modelinizi başlatmak ve kendi özel görevinize göre ince ayar yapmak için önceden eğitilmiş bir yerleştirme kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtTn9o4MYAqD"
   },
   "source": [
    "> Soru: Hangi düzeyde belirteç kullanmalıyım? Hangi embedi  seçmeliyim?\n",
    "\n",
    "Sorununuza bağlı. Karakter düzeyinde tokenization/embed ve sözcük düzeyinde word-level-tokenization/embed deneyebilir ve hangisinin en iyi performansı gösterdiğini görebilirsiniz. Bunları istiflemeyi bile deneyebilirsiniz (örneğin, embed katmanlarınızın çıktılarını tf.keras.layers.concatenate kullanarak birleştirmek).\n",
    "\n",
    "Önceden eğitilmiş sözcük yerleştirmeleri arıyorsanız, Word2vec yerleştirmeleri, GloVe yerleştirmeleri ve TensorFlow Hub'da bulunan seçeneklerin çoğu, başlamak için harika yerlerdir.\n",
    "\n",
    "> 🔑 Not: Önceden eğitilmiş bir bilgisayarlı görü modelini aramaya benzer şekilde, probleminiz için kullanmak üzere önceden eğitilmiş sözcük yerleştirmelerini arayabilirsiniz. \"TensorFlow'da önceden eğitilmiş kelime yerleştirmelerini kullan\" gibi bir şey aramayı deneyin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZKhlpoweUcQ"
   },
   "source": [
    "### Metin Vektörleştirme\n",
    "\n",
    "İlk önce tokenizasyon (kelimelerimizi sayılarla eşleştirme) alıştırması yapacağız. Sözlerimizi simgeleştirmek için, yararlı önişleme katmanı `tf.keras.layers.experimental.preprocessing.TextVectorization` kullanacağız.\n",
    "\n",
    "TextVectorization katmanı aşağıdaki parametreleri alır:\n",
    "- **max_tokens**<br>\n",
    "Kelime dağarcığınızdaki maksimum kelime sayısı (örneğin, metninizdeki 20000 veya benzersiz kelime sayısı), OOV (kelime dışı) belirteçleri için bir değer içerir.\n",
    "- **standardize**<br>\n",
    "Metni standartlaştırma yöntemi. Varsayılan, metni alçaltan ve tüm noktalama işaretlerini kaldıran \"`lower_and_strip_punctuation`\"dır.\n",
    "- **split**<br>\n",
    "Metin nasıl bölünür, varsayılan olarak boşluklara bölünen \"split\"tir.\n",
    "- **ngrams**<br>\n",
    "Belirteç başına kaç sözcük içerecek, örneğin, ngrams=2 belirteçleri 2'lik sürekli dizilere böler.\n",
    "- **output_mode**<br>\n",
    "Belirteçler nasıl çıkarılır, \"int\" (tamsayı eşleme), \"binary\" (tek-sıcak kodlama), \"count\" veya \"tf-idf\" olabilir. \n",
    "- **output_sequence_length**<br>\n",
    "Çıktı için belirtilmiş dizinin uzunluğu. Örneğin, çıktı_dizi_uzunluk=150 ise, tüm belirteçli diziler 150 belirteç uzunluğunda olacaktır.\n",
    "- **pad_to_max_tokens**<br>\n",
    "True (varsayılan) ise, sözlükteki benzersiz jeton sayısı max_tokens'den az olsa bile çıktı özelliği ekseni max_tokens olarak doldurulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hi10JJDNWyJe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=None,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\", \n",
    "                                    ngrams=None, \n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=None,\n",
    "                                    pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhYJxrPDe5iv"
   },
   "source": [
    "Bir TextVectorization nesnesini varsayılan ayarlarla başlattık, ancak bunu kendi kullanım durumumuz için biraz özelleştirelim. Özellikle `max_tokens` ve `output_sequence_length` için değerler belirleyelim.\n",
    "\n",
    "`max_tokens` (kelimelerdeki kelime sayısı) için 10.000'in katları (10.000, 20.000, 30.000) veya metninizdeki tam benzersiz kelime sayısı (ör. 32.179) ortak değerlerdir. Kullanım durumumuz için 10.000 kullanacağız.\n",
    "\n",
    "Ve `output_sequence_length` için, eğitim setindeki Tweet başına ortalama jeton sayısını kullanacağız. Ama önce onu bulmamız gerekecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq56tBhoe1jL",
    "outputId": "9974f4f3-a6ab-4bf0-c271-3e2902f51980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eğitim Tweetlerinde ortalama jeton (kelime) sayısını bulma\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3D4pQlAfLVq"
   },
   "source": [
    "Şimdi özel parametrelerimizi kullanarak başka bir TextVectorization nesnesi oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ycryi55wfCys"
   },
   "outputs": [],
   "source": [
    "# Metin vektörleştirme değişkenlerini ayarlayın\n",
    "max_vocab_length = 10000 # kelime dağarcığımızda bulunması gereken maksimum kelime sayısı\n",
    "max_length = 15 # dizilerimiz maksimum uzunluk olacaktır (ör. modelimiz bir Tweetten kaç kelime görüyor?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCpBcdL2fZJN"
   },
   "source": [
    "Güzel! `TextVectorization` örneğimizi text_vectorizer verilerimizle eşleştirmek için, eğitim metnimizi iletirken `adapt()` yöntemini çağırabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9x19qQgkfMyS"
   },
   "outputs": [],
   "source": [
    "# Metin vektörleştiriciyi eğitim metnine fit etme\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB0Y-w6XfpTL"
   },
   "source": [
    "Eğitim verileri eşlendi! Text_vectorizer'ımızı özel bir cümle üzerinde deneyelim (eğitim verilerinde görebileceğinize benzer bir cümle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQCm_7CBfcBO",
    "outputId": "3fdf51f9-224d-4502-8da8-de27a8c78a14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Örnek cümle oluştur ve onu belirt\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flk_LoetftYl"
   },
   "source": [
    "Harika, görünüşe göre metnimizi sayılara dönüştürmenin bir yolu var (bu durumda, kelime düzeyinde simgeleştirme). Döndürülen tensörün sonundaki 0'lara dikkat edin, bunun nedeni output_sequence_length=15 olarak ayarlamış olmamızdır, yani text_vectorizer'a ilettiğimiz dizinin boyutu ne olursa olsun, her zaman 15 uzunluğunda bir dizi döndürür.\n",
    "\n",
    "Birkaç rastgele cümle üzerinde text_vectorizer'ımızı denemeye ne dersiniz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1GuyRhUfrEc",
    "outputId": "26f2e856-f8d3-4f9b-b446-6c1e7f87b43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "U.S. Forest Service firefighter David Ruhl 38 died in the 'Frog Fire' in the Modoc National Forest. He had been temporarily reassigned      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[  69,  188,  386, 1674, 1691, 8927,    1,  579,    4,    2,    1,\n",
       "          42,    4,    2,    1]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkrb5ms-f4A4"
   },
   "source": [
    "İyi görünüyor! Son olarak, `get_vocabulary()` yöntemini kullanarak sözlüğümüzdeki benzersiz belirteçleri kontrol edebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQLFPUwpfz-a",
    "outputId": "ba06d0ea-30db-4af7-a8ed-fd1dcc2035a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Kelime dağarcığındaki benzersiz kelimeleri alın\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:] \n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrq1txhCgFHS"
   },
   "source": [
    "Gömme Katmanı Kullanarak Gömme Oluşturma\n",
    "Metnimizi sayılarla eşleştirmenin bir yolu var. Bir adım daha ileri gidip bu sayıları bir gömme haline getirmeye ne dersiniz?\n",
    "\n",
    "Bir gömmenin güçlü yanı, eğitim sırasında öğrenilebilmesidir. Bu, yalnızca statik olmaktan ziyade (örneğin 1 = I, 2 = love, 3 = TensorFlow), bir kelimenin sayısal gösteriminin, bir model veri örneklerinden geçerken geliştirilebileceği anlamına gelir.\n",
    "\n",
    "`tf.keras.layers.Embedding` katmanını kullanarak bir kelimenin gömülmesinin nasıl göründüğünü görebiliriz.\n",
    "\n",
    "Burada ilgilendiğimiz ana parametreler şunlardır:\n",
    "\n",
    "- **input_dim** <br>\n",
    "Sözlüğün boyutu \n",
    "- **output_dim**<br>\n",
    "Çıktı gömme vektörünün boyutu, örneğin 100 değeri, her kelime için 100 boyutunda bir özellik vektörü verir.\n",
    "- **embeddings_initializer**<br>\n",
    "Gömme matrisi nasıl başlatılır, varsayılan değer, tek tip dağılımla gömme matrisini rastgele başlatan \"tek biçimli\"dir. Bu, önceden öğrenilmiş yerleştirmeleri kullanmak için değiştirilebilir.\n",
    "- **input_length**<br> Gömme katmanına geçirilen dizilerin uzunluğu.\n",
    "\n",
    "Bunları bilerek bir gömme katmanı yapalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4-K6s-qf9RA",
    "outputId": "89dd953a-6401-445e-b1e8-bca942f464fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f0195623e90>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                             output_dim=128, \n",
    "                             embeddings_initializer=\"uniform\",\n",
    "                             input_length=max_length) \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFhrXSpn6Px_"
   },
   "source": [
    "Mükemmel, TensoFlow katmanının nasıl gömüldüğünü fark ettiniz mi? Bu önemlidir çünkü onu bir modelin parçası olarak kullanabiliriz, yani parametreleri (kelime temsilleri) model öğrendikçe güncellenebilir ve geliştirilebilir.\n",
    "\n",
    "Örnek bir cümle üzerinde deneyelim mi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyGpmm5U52o_",
    "outputId": "f44c9b46-4c22-489f-e929-64396ce50e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Army names 10th Mountain units for Iraq Afghanistan deployments (Deeds) http://t.co/N6ZfLXIGvr      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.00916288, -0.02020576,  0.01051251, ...,  0.03743795,\n",
       "         -0.03013742, -0.02531119],\n",
       "        [ 0.04532088,  0.02299361,  0.01219423, ..., -0.00065058,\n",
       "         -0.04569644, -0.00531676],\n",
       "        [ 0.03858428, -0.04181042, -0.00797512, ..., -0.00329729,\n",
       "          0.03181828,  0.04978368],\n",
       "        ...,\n",
       "        [ 0.00141954, -0.01528921,  0.04304833, ..., -0.01062925,\n",
       "          0.01877917, -0.00428162],\n",
       "        [ 0.00141954, -0.01528921,  0.04304833, ..., -0.01062925,\n",
       "          0.01877917, -0.00428162],\n",
       "        [ 0.00141954, -0.01528921,  0.04304833, ..., -0.01062925,\n",
       "          0.01877917, -0.00428162]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQuonqoP6pHk"
   },
   "source": [
    "Cümledeki her belirteç, 128 uzunlukta bir özellik vektörüne dönüştürülür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slTogdAS6Xv0",
    "outputId": "23950ee3-07a3-4437-8524-36f34f0b10f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.00916288, -0.02020576,  0.01051251,  0.01018524, -0.04450629,\n",
       "        0.01370009,  0.01044489, -0.01513488,  0.02855153,  0.01395481,\n",
       "       -0.04568119, -0.00575911,  0.01966823, -0.04059171,  0.0413805 ,\n",
       "        0.03656509, -0.02095454, -0.04788685, -0.02226297,  0.04037564,\n",
       "       -0.03191366,  0.03968054, -0.00194321,  0.02069068,  0.0350836 ,\n",
       "        0.02134537,  0.01469893, -0.02956121, -0.02796942, -0.03294774,\n",
       "       -0.04563676, -0.03714399,  0.01066669,  0.03298349, -0.00739118,\n",
       "        0.04917097,  0.01289347,  0.03903702,  0.02170446,  0.02120433,\n",
       "        0.01201127, -0.01070263,  0.0261583 ,  0.03698863,  0.01283456,\n",
       "       -0.01727299, -0.00012108, -0.0367375 , -0.01463311, -0.04898279,\n",
       "       -0.00069792, -0.00546343,  0.02455739,  0.03335546, -0.03360651,\n",
       "       -0.03045735,  0.00717491, -0.03701036, -0.01086336,  0.03041612,\n",
       "       -0.01906449,  0.02496426, -0.03597245, -0.01636804, -0.00832563,\n",
       "        0.03531268,  0.00391679,  0.00113746,  0.02531954, -0.04372667,\n",
       "        0.01609613, -0.04192771,  0.02265961,  0.01025601,  0.04619921,\n",
       "       -0.00561135,  0.03279671, -0.04784563,  0.02746815,  0.04743092,\n",
       "       -0.04517381, -0.03620393,  0.03094572,  0.0469407 , -0.02911168,\n",
       "        0.02919107,  0.0493275 , -0.0354128 , -0.00053966, -0.01730473,\n",
       "       -0.03506305,  0.03537161,  0.00785895,  0.03800782,  0.00921674,\n",
       "        0.03885179, -0.028087  ,  0.01270168,  0.04836855, -0.04588796,\n",
       "        0.01885916,  0.0454084 ,  0.00161005, -0.04547844,  0.0299739 ,\n",
       "        0.01862308, -0.00661734, -0.03526626, -0.00043763, -0.02819604,\n",
       "       -0.03603878, -0.03872228,  0.00732009, -0.01773995,  0.04899145,\n",
       "       -0.00022688, -0.01785977, -0.04193083,  0.00570047,  0.0428207 ,\n",
       "       -0.03000025,  0.0157868 ,  0.01703984, -0.02578779,  0.03508879,\n",
       "        0.03743795, -0.03013742, -0.02531119], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXHnOtkM6t9V"
   },
   "source": [
    "🔑 Not: Önceki iki kavram (belirteçleştirme ve yerleştirme) birçok NLP görevinin temelidir. Bu nedenle, herhangi bir şeyden emin değilseniz, anlayışınıza daha fazla yardımcı olmak için kendi deneylerinizi araştırdığınızdan ve yürüttüğünüzden emin olun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5e0ekTj6_G8"
   },
   "source": [
    "## Bir Metin Veri Kümesini Modelleme\n",
    "\n",
    "Girdilerinizi ve çıktılarınızı hazırladıktan sonra, aradaki boşluğu kapatmak için hangi makine öğrenimi modelinin oluşturulacağını bulmak meselesidir.\n",
    "\n",
    "Artık metin verilerimizi sayılara dönüştürmenin bir yolu olduğuna göre, onu modellemek için makine öğrenimi modelleri oluşturmaya başlayabiliriz.\n",
    "\n",
    "Bol bol pratik yapmak için, her biri kendi deneyi olan bir dizi farklı model oluşturacağız. Daha sonra her modelin sonuçlarını karşılaştıracağız ve hangisinin en iyi performansı gösterdiğini göreceğiz.\n",
    "\n",
    "Daha spesifik olarak, aşağıdakileri inşa edeceğiz:\n",
    "\n",
    "- Model 0: Naive Bayes (temel)\n",
    "- Model 1: İleri beslemeli sinir ağı (yoğun model)\n",
    "- Model 2: LSTM modeli\n",
    "- Model 3: GRU modeli\n",
    "- Model 4: Çift Yönlü-LSTM modeli\n",
    "- Model 5: 1B Evrişimli Sinir Ağı\n",
    "- Model 6: TensorFlow Hub Önceden Eğitilmiş Özellik Çıkarıcı\n",
    "- Model 7: Eğitim verilerinin %10 ile model 6'nın aynısı \n",
    "\n",
    "Model 0, diğer daha derin modellerin birbirini yenmesini bekleyeceğimiz bir temel elde etmek için en basit olanıdır.\n",
    "\n",
    "Her deney aşağıdaki adımlardan geçecektir:\n",
    "\n",
    "- Modeli oluşturun\n",
    "- Modeli eğit\n",
    "- Modelle tahminler yapın\n",
    "- Daha sonra karşılaştırma için tahmin değerlendirme metriklerini takip edin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENfJlJZJ7bIv"
   },
   "source": [
    "### Model 0: Temel oluşturma\n",
    "\n",
    "Tüm makine öğrenimi modelleme deneylerinde olduğu gibi, bir temel model oluşturmak önemlidir, böylece gelecekteki deneyler için üzerine inşa edebileceğiniz bir kıyaslama elde edersiniz.\n",
    "\n",
    "Temel çizgimizi oluşturmak için, kelimelerimizi sayılara dönüştürmek için TF-IDF (terim frekansı-ters belge frekansı) formülünü kullanarak bir Scikit-Learn Pipeline oluşturacağız ve ardından bunları Multinomial Naive Bayes algoritması ile modelleyeceğiz. Bu, Scikit-Learn makine öğrenimi haritasına başvurularak seçildi.\n",
    "\n",
    "📖 TD-IDF algoritması hakkında okunması gereken bir makale: https://www.onely.com/blog/what-is-tf-idf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IlOnPhf6gwI",
    "outputId": "0298e9de-399c-4528-8432-f9994e0919ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()),# tfidf kullanarak kelimeleri sayılara dönüştürün\n",
    "                    (\"clf\", MultinomialNB()) # metni modelle\n",
    "])\n",
    "\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yc5ej1TO76tc"
   },
   "source": [
    "`Multinomial Naive Bayes` gibi sığ bir model kullanmanın yararı, eğitimin çok hızlı olmasıdır. Modelimizi değerlendirelim ve temel metriğimizi bulalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlY07nCo72Lq",
    "outputId": "34376ecb-1931-4afa-daf8-9ceb489823ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM4s6E1_8R-u"
   },
   "source": [
    "Temel modelimiz ile bazı tahminler yapmaya ne dersiniz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeL-t7mW78tD",
    "outputId": "8f6be26e-370e-4e54-dab3-5ee12184633e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AcLAuo-8Yv4"
   },
   "source": [
    "### Model Deneylerimiz İçin Bir Değerlendirme Fonksiyonu Oluşturma\n",
    "\n",
    "Bunları olduğu gibi değerlendirebiliriz, ancak ileride birkaç modeli aynı şekilde değerlendireceğimiz için, bir dizi tahmin ve kesinlik etiketi alan ve aşağıdakileri hesaplayan bir yardımcı fonksiyon oluşturalım:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "🔑 Not: Bir sınıflandırma sorunuyla uğraştığımız için yukarıdaki metrikler en uygun olanlardır. Bir regresyon problemi ile çalışıyor olsaydık, MAE (ortalama mutlak hata) gibi diğer metrikler daha iyi bir seçim olurdu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHNiznvA8S_X",
    "outputId": "400b027a-80cb-4652-f591-51915427cbc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'f1': 0.7862189758049549,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706}"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results\n",
    "\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tShs210k88Gj"
   },
   "source": [
    "### Model 1: Basit Bir Yoğun (Dense) Model\n",
    "\n",
    "İnşa edeceğimiz ilk derin model, tek katmanlı yoğun bir modeldir. Aslında, zar zor tek bir katmana sahip olacak.\n",
    "\n",
    "Metnimizi ve etiketlerimizi girdi olarak alacak, metni simgeleştirecek, bir gömme oluşturacak, gömmenin ortalamasını bulacak (Küresel Ortalama Havuzlamayı kullanarak) ve ardından ortalamayı bir çıktı birimi ve bir sigmoid etkinleştirme işleviyle tam bağlantılı bir katmandan geçirecektir.\n",
    "\n",
    "Önceki cümle kulağa ağız dolusu gibi geliyorsa, onu kodladığımızda mantıklı olacaktır (şüpheniz varsa, kodlayın)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tVprZT4M8usz"
   },
   "outputs": [],
   "source": [
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF4VWYC-9LDb"
   },
   "source": [
    "Şimdi kullanıma hazır bir TensorBoard geri çağırma işlevimiz var, hadi ilk derin modelimizi oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "aD4VgExj9Gm8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# girdiler 1 boyutlu dizelerdir\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "\n",
    "# giriş metnini sayılara çevirin\n",
    "x = text_vectorizer(inputs) \n",
    "\n",
    "# numaralandırılmış sayıların bir gömülmesini oluşturun\n",
    "x = embedding(x) \n",
    "\n",
    "# gömmenin boyutunu azaltın (modeli bu katman olmadan çalıştırmayı deneyin ve ne olduğunu görün)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "# çıktı katmanını oluşturun, ikili çıktılar isteyin, bu nedenle sigmoid aktivasyonunu kullanın\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) \n",
    "\n",
    "# modeli oluşturun\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibXHh7OU9Xi3"
   },
   "source": [
    "İyi görünüyor. Modelimiz girdi olarak 1 boyutlu bir dize alır (bizim durumumuzda bir Tweet), ardından text_vectorizer kullanarak dizeyi belirtir ve gömmeyi kullanarak bir gömme oluşturur.\n",
    "\n",
    "Daha sonra (isteğe bağlı olarak) çıktı katmanına ilettiğimiz tensörün boyutsallığını azaltmak için gömme katmanının çıktılarını havuzlarız.\n",
    "\n",
    "Son olarak, havuzlama katmanının çıktısını sigmoid aktivasyonu ile yoğun bir katmana geçiriyoruz (sorunumuz ikili sınıflandırma olduğu için sigmoid kullanıyoruz).\n",
    "\n",
    "Modelimizi verilerle fit etmeden önce onu derlememiz gerekiyor. İkili sınıflandırma ile çalıştığımız için, kayıp fonksiyonumuz ve Adam optimize edici olarak \"binary_crossentropy\" kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orwTMvK49MA3",
    "outputId": "977a144f-d869-481b-b6e0-18ac67b67966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# model derlendi. Özetine göz atalım\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHKC6Ijw9oIu"
   },
   "source": [
    "Eğitilebilir parametrelerin çoğu, gömme katmanında bulunur. 10.000 (input_dim=10000) boyutunda bir sözcük dağarcığı için 128 boyutunda (output_dim=128) bir yerleştirme oluşturduğumuzu, dolayısıyla 1.280.000 eğitilebilir parametre oluşturduğumuzu hatırlayın.\n",
    "\n",
    "Pekala, modelimiz derlendi, 5 epoch kullanarak eğitim verilerimize fit edelim. Modelimizin eğitim ölçümlerinin log'lara kaydedildiğinden emin olmak için TensorBoard geri çağırma işlevimizi de ileteceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8Z6pDQ49lul",
    "outputId": "19a9ec21-845e-4c72-836c-946317c6a8f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20210801-153638\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 17ms/step - loss: 0.6132 - accuracy: 0.6850 - val_loss: 0.5371 - val_accuracy: 0.7559\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.4427 - accuracy: 0.8168 - val_loss: 0.4697 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.3479 - accuracy: 0.8606 - val_loss: 0.4582 - val_accuracy: 0.7913\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.2851 - accuracy: 0.8911 - val_loss: 0.4611 - val_accuracy: 0.7874\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.2387 - accuracy: 0.9107 - val_loss: 0.4775 - val_accuracy: 0.7822\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(\n",
    "    train_sentences, \n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
    "                                           experiment_name=\"simple_dense_model\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttK9XFsg9zUb"
   },
   "source": [
    "Güzel! Bu kadar basit bir model kullandığımız için her epoch çok hızlı işliyor. Modelimizin doğrulama setindeki performansını kontrol edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZ0IFfJH9uJJ",
    "outputId": "9a7dad1a-9a86-4e92-8447-96103fad100c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47749000787734985, 0.7821522355079651]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlIn0BaI947P"
   },
   "source": [
    "Ve modelimizin eğitim loglarını TensorBoard ile takip ettiğimize göre, onları görselleştirmeye ne dersiniz? Bunu, TensorBoard log dosyalarımızı (model_logs dizininde bulunur) TensorBoard.dev'e yükleyerek yapabiliriz.\n",
    "\n",
    "🔑 Not: TensorBoard.dev'e yüklediğiniz her şeyin herkese açık hale geleceğini unutmayın. Paylaşmak istemediğiniz antrenman kayıtları varsa yüklemeyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "a0309UbO92zL"
   },
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir ./model_logs \\\n",
    "#   --name \"First deep model on text data\" \\\n",
    "#   --description \"Trying a dense model with an embedding layer\" \\\n",
    "#   --one_shot # exits the uploader when upload has finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNmgnCo3qz4r"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tensorboard-dense-model-training-curves.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI7eTabL-D5h"
   },
   "source": [
    "Güzel! Bunlar bazı renkli eğitim eğrileri. Modelin fazla mı yoksa yetersiz mi olduğunu söyler misiniz? İlk derin modelimizi oluşturduk ve eğittik, bir sonraki adım onunla bazı tahminler yapmak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GB-1KXKz-EG4",
    "outputId": "10a12337-ee39-4f0d-c80d-f279b17242d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38384166],\n",
       "       [0.72483045],\n",
       "       [0.997633  ],\n",
       "       [0.11788377],\n",
       "       [0.10144898],\n",
       "       [0.9263861 ],\n",
       "       [0.92003554],\n",
       "       [0.99293476],\n",
       "       [0.96582043],\n",
       "       [0.26976743]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tahminler yapma\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCcJlcmu-J94"
   },
   "source": [
    "Son katmanımız bir sigmoid aktivasyon fonksiyonu kullandığından, tahminlerimizi olasılıklar şeklinde geri alıyoruz.\n",
    "\n",
    "Bunları tahmin sınıflarına dönüştürmek için `tf.round()` kullanacağız, yani 0,5'in altındaki tahmin olasılıkları 0'a ve 0,5'in üzerindekiler 1'e yuvarlanacaktır.\n",
    "\n",
    "🔑 Not: Pratikte, bir sigmoid tahmin olasılığının çıktı eşiğinin mutlaka 0,5 olması gerekmez. Örneğin, test yoluyla, seçtiğiniz değerlendirme metrikleri için 0,25'lik bir kesmenin daha iyi olduğunu görebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKLK7kGG-F7X",
    "outputId": "cafc1c89-cce8-4bcc-ad7d-77a580b8d508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tahmin olasılıklarını tek boyutlu float tensöre dönüştürün\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wb_BfYMVsIat"
   },
   "source": [
    "Şimdi modelimizin tahminlerini sınıflar şeklinde elde ettik, onları temel doğruluk doğrulama etiketleriyle karşılaştırmak için `calculate_results()` işlevimizi kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3V33T1No-Xsu",
    "outputId": "032978ad-9181-490e-ecbb-6a92662e5e27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.21522309711287,\n",
       " 'f1': 0.779088324447517,\n",
       " 'precision': 0.7868451603977311,\n",
       " 'recall': 0.7821522309711286}"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = calculate_results(y_true=val_labels, y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC7r2EnhsTQE"
   },
   "source": [
    "İlk derin modelimizi temel modelimizle karşılaştırmaya ne dersiniz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlWVxE1hsP3C",
    "outputId": "bdceb232-5fac-4baf-8323-daa60d135ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lguZacVOsYuk"
   },
   "source": [
    "Bu tür bir karşılaştırmayı (yeni modele kıyasla temel) birkaç kez yapacağımız için, bize yardımcı olacak bir fonksiyon oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOGijcNlsWgu",
    "outputId": "eedca7bd-8f5e-489d-b409-b90552eaa98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.22, Difference: -1.05\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUhMvbpE0rwS"
   },
   "source": [
    "# Tekrarlayan Sinir Ağları (RNN'ler)\n",
    "\n",
    "Bir sonraki modelleme deneylerimiz için, Tekrarlayan Sinir Ağı (RNN) adı verilen özel bir tür sinir ağı kullanacağız.\n",
    "\n",
    "Bir RNN'nin önermesi basittir: gelecekte size yardımcı olması için geçmişten gelen bilgileri kullanın (tekrarlayan terimi buradan gelir). Başka bir deyişle, bir girdi (X) alın ve önceki tüm girdilere dayanarak bir çıktı (y) hesaplayın.\n",
    "\n",
    "Bu kavram, özellikle doğal dil metinlerinin (Tweet'lerimiz gibi) pasajları gibi dizilerle uğraşırken yararlıdır.\n",
    "\n",
    "Örneğin, bu cümleyi okuduğunuzda, mevcut köpek kelimesinin anlamını deşifre ederken önceki kelimeleri bağlam içine alırsınız. Geçerli bir kelime olan \"köpek\" kelimesini sonuna koydum ama cümlenin geri kalanı bağlamında bir anlam ifade etmiyor.\n",
    "\n",
    "Bir RNN bir metin dizisine (zaten sayısal biçimde) baktığında, öğrendiği modeller dizinin sırasına göre sürekli olarak güncellenir.\n",
    "\n",
    "Basit bir örnek için iki cümle alın:\n",
    "\n",
    "- Geçen hafta büyük deprem oldu, değil mi?\n",
    "- Geçen hafta büyük bir deprem olmadı.\n",
    "Her ikisi de tamamen aynı kelimeleri içerir, ancak farklı anlamlara sahiptir. Sözcüklerin sırası anlamı belirler (noktalama işaretlerinin de anlamı dikte ettiği tartışılabilir, ancak basitlik adına, kelimelere odaklanalım).\n",
    "\n",
    "Tekrarlayan sinir ağları, bir dizi dizi tabanlı problem için kullanılabilir:\n",
    "\n",
    "- **Bire bir:**<br> \n",
    "bir girdi, bir çıktı, görüntü sınıflandırması gibi.\n",
    "- **Birden çoğa:**<br> \n",
    "bir giriş, resim yazısı gibi birçok çıkış (resim girişi, resim yazısı çıkışı olarak bir metin dizisi).\n",
    "- **Çoktan bire:**<br>\n",
    "birçok girdi, metin sınıflandırması gibi bir çıktı (bir Tweet'i gerçek hata veya gerçek hata değil olarak sınıflandırma).\n",
    "- **Çoktan çoğa:**<br>\n",
    "birçok girdi, makine çevirisi (İngilizceden İspanyolcaya çevirme) veya konuşmayı metne (giriş olarak ses dalgası, çıktı olarak metin) gibi birçok çıktı.\n",
    "\n",
    "Vahşi doğada RNN'lerle karşılaştığınızda, büyük olasılıkla aşağıdakilerin varyantlarıyla karşılaşacaksınız:\n",
    "\n",
    "- Uzun kısa süreli hafıza hücreleri (LSTM'ler).\n",
    "- Kapılı yinelenen birimler (GRU'lar).\n",
    "- Çift yönlü RNN'ler (bir dizi boyunca ileri ve geri, soldan sağa ve sağdan sola geçer).\n",
    "\n",
    "Bunların her birinin ayrıntılarına girmek bu defterin kapsamı dışındadır (bunun yerine onları kullanmaya odaklanacağız), şimdilik bilmeniz gereken en önemli şey, dizileri modellemede çok etkili olduklarını kanıtladıklarıdır.\n",
    "\n",
    "Yazmak üzere olduğumuz kodun perde arkasında neler olduğunu daha iyi anlamak için aşağıdaki kaynakları tavsiye ederim:\n",
    "> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) \n",
    "> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) \n",
    "> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxLktGhX1w3c"
   },
   "source": [
    "## Model 2: LSTM\n",
    "\n",
    "RNN'lerin ne olduğu ve ne işe yaradığıyla ilgili tüm bu konuşmalardan sonra, eminim siz de bir tane oluşturmaya heveslisinizdir. LSTM destekli bir RNN ile başlayacağız.\n",
    "\n",
    "TensorFlow'da LSTM hücresinin (LSTM hücresi ve LSTM katmanı genellikle birbirinin yerine kullanılır) gücünden yararlanmak için [`tensorflow.keras.layers.LSTM()`](https://www.tensorflow.org/) kullanacağız. api_docs/python/tf/keras/layers/LSTM).\n",
    "\n",
    "Modelimiz `model_1` ile çok benzer bir yapı alacak:\n",
    "\n",
    "```\n",
    "Girdi (metin) -> Simgeleştir -> Gömme -> Katmanlar -> Çıktı (etiket olasılığı)\n",
    "```\n",
    "\n",
    "Temel fark, gömme ve çıktımız arasına bir LSTM katmanı ekleyeceğimiz olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iabDi0ts1XUZ",
    "outputId": "8380bd02-f902-4c1b-bd0a-e88589cca2bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# LSTM oluşturma\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaArBEW-2rn9"
   },
   "source": [
    "> 🔑 **Not:** [TensorFlow LSTM katmanı](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) için belgeleri okurken, çok sayıda parametre bulacaksınız . Bunların çoğu, mümkün olduğunca hızlı hesaplanmalarını sağlamak için ayarlanmıştır. Ayarlamak isteyeceğiniz başlıca olanlar \"units\" (gizli birimlerin sayısı) ve \"return_sequences\"dir (LSTM veya diğer tekrarlayan katmanları istiflerken bunu \"True\" olarak ayarlayın).\n",
    "\n",
    "Şimdi LSTM modelimizi oluşturduk, hadi onu `\"binary_crossentropy\"` kaybı ve Adam optimizer kullanarak derleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khUF70ZU16XV",
    "outputId": "1e207336-53b2-4160-c956-0770e22cdb7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Modelimizi fit etmeden önce bir özet geçelim:\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8-WABdB3Kr0"
   },
   "source": [
    "İyi görünüyor! LSTM katmanımızda \"model_1\"den çok daha fazla eğitilebilir parametre fark edeceksiniz.\n",
    "\n",
    "Bu sayının nereden geldiğini bilmek istiyorsanız, bir LSTM hücresindeki parametre sayısını hesaplamak için yukarıdaki kaynakları ve aşağıdakileri incelemenizi öneririm:\n",
    "* [LSTM hücresindeki parametre sayısını hesaplamak için Stack Overflow yanıtı](https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network ) yazan Marcin Możejko\n",
    "* [LSTM birimindeki ve katmanındaki parametre sayısı hesaplanıyor](https://medium.com/@priyadarshi.cse/calcizing-number-of-parameters-in-a-lstm-unit-layer-7e491978e1e4) Shridhar Priyadarshi\n",
    "\n",
    "Şimdi ilk RNN modelimiz derlendi, onu eğitim verilerimizle fit edelim, doğrulama verileri üzerinde doğrulayalım ve TensorBoard geri çağrımızı kullanarak eğitim parametrelerini takip edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4QvDN33234u",
    "outputId": "b69884ee-3285-46d9-ce6b-213ba1f6b6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20210801-153658\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 23ms/step - loss: 0.2145 - accuracy: 0.9234 - val_loss: 0.5332 - val_accuracy: 0.7861\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1564 - accuracy: 0.9418 - val_loss: 0.5328 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.1265 - accuracy: 0.9527 - val_loss: 0.6293 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1035 - accuracy: 0.9575 - val_loss: 0.7793 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0826 - accuracy: 0.9685 - val_loss: 1.1029 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "model_2_history = model_2.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"LSTM\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPR9BK7sNmhD"
   },
   "source": [
    "Güzel! LSTM hücrelerini kullanan ilk eğitimli RNN modelimize sahibiz. Onunla bazı tahminler yapalım. Son katmandaki sigmoid aktivasyon fonksiyonu nedeniyle daha önce olduğu gibi aynı şey olacak, modelimizde `predict()` yöntemini çağırdığımızda sınıflardan ziyade tahmin olasılıklarını döndürecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMHMFVvTNimz",
    "outputId": "5d473ac3-cf11-4dca-de73-8b075a362c43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1), array([[8.7842321e-01],\n",
       "        [8.5219616e-01],\n",
       "        [9.9986124e-01],\n",
       "        [5.6012526e-02],\n",
       "        [4.8184194e-04],\n",
       "        [9.9966288e-01],\n",
       "        [9.8856550e-01],\n",
       "        [9.9991667e-01],\n",
       "        [9.9985754e-01],\n",
       "        [8.9258754e-01]], dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM8u8g4uN1od"
   },
   "source": [
    "Bu tahmin olasılıklarını en yakın tam sayıya yuvarlayarak tahmin sınıflarına dönüştürebiliriz (varsayılan olarak 0,5'in altındaki tahmin olasılıkları 0'a, 0,5'in üzerindekiler ise 1'e gidecektir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-VR4Dl_NvW5",
    "outputId": "abd05158-ef78-4a9f-cc7c-b66c66cdcb95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC1Dh9S3N6jS"
   },
   "source": [
    "Güzel, şimdi LSTM modelimizi değerlendirmek için `caculate_results()` işlevimizi ve bunu temel modelimizle karşılaştırmak için `Compare_baseline_to_new_results()` işlevimizi kullanalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WoJgAF0N41B",
    "outputId": "151682a7-f722-4013-a6b0-e1ed45f82869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'f1': 0.7782879110458442,\n",
       " 'precision': 0.7783847812585096,\n",
       " 'recall': 0.7782152230971129}"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0hHX7d4N_w2",
    "outputId": "889ab410-9e70-4a78-8e5d-2355ec9a0204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.82, Difference: -1.44\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1ucdE6sPW6f"
   },
   "source": [
    "## Model 3: GRU\n",
    "\n",
    "Bir başka popüler ve etkili RNN bileşeni, GRU veya kapılı tekrarlayan birimdir. GRU hücresi, bir LSTM hücresine benzer özelliklere sahiptir ancak daha az parametreye sahiptir.\n",
    "\n",
    "GRU hücresini TensorFlow'da kullanmak için [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) sınıfını çağırabiliriz.\n",
    "\n",
    "GRU destekli modelin mimarisi, kullandığımız yapıyla aynı olacak:\n",
    "\n",
    "```\n",
    "Girdi (metin) -> Simgeleştir -> Gömme -> Katmanlar -> Çıktı (etiket olasılığı)\n",
    "```\n",
    "Yine, tek fark, gömme ve çıktı arasında kullandığımız katman(lar) olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6cJ_YmkKOFBr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GRU(64)(x) \n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Udcye03sPgQ4"
   },
   "source": [
    "TensorFlow, modellerimizde GRU hücresi gibi güçlü bileşenleri kullanmayı kolaylaştırır. Ve şimdi üçüncü modelimiz yapıldı, eskisi gibi derleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BtJjGx3PbpT",
    "outputId": "9327e710-8aa2-4596-e4c5-f0d9322ce6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h37qUDfdPm1y"
   },
   "source": [
    "`model_2` (LSTM) ve `model_3` (GRU) arasındaki eğitilebilir parametre sayısındaki farka dikkat edin. Fark, GRU hücresinden daha fazla eğitilebilir parametreye sahip LSTM hücresinden gelir.\n",
    "\n",
    "Modelimize daha önce yaptığımız gibi fit edeceğiz. Ayrıca, `create_tensorboard_callback()` fonksiyonumuzu kullanarak model sonuçlarımızı takip edeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKldDm_0PkIq",
    "outputId": "b5a7894b-3b5e-464d-d9ce-2e6334d2aa65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/GRU/20210801-153742\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 21ms/step - loss: 0.1627 - accuracy: 0.9334 - val_loss: 0.7266 - val_accuracy: 0.7861\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0824 - accuracy: 0.9702 - val_loss: 0.9151 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0749 - accuracy: 0.9721 - val_loss: 1.0135 - val_accuracy: 0.7782\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0609 - accuracy: 0.9766 - val_loss: 1.2912 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.0507 - accuracy: 0.9783 - val_loss: 1.2469 - val_accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "model_3_history = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRmqmiUTP4P6"
   },
   "source": [
    "TensorFlow'daki GRU hücresinin optimize edilmiş varsayılan ayarları nedeniyle, eğitim hiç uzun sürmez. Doğrulama örnekleri üzerinde bazı tahminlerde bulunma zamanı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGBENxwGP1eo",
    "outputId": "e459029f-3298-423f-8734-195106b78eba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1), array([[4.4600765e-04],\n",
       "        [7.4906093e-01],\n",
       "        [9.9987340e-01],\n",
       "        [1.6632774e-01],\n",
       "        [8.7559012e-05],\n",
       "        [9.9979585e-01],\n",
       "        [7.3085886e-01],\n",
       "        [9.9996459e-01],\n",
       "        [9.9990916e-01],\n",
       "        [9.7049451e-01]], dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnwopKCsQDAX"
   },
   "source": [
    "Yine, onları yuvarlayarak tahmin sınıflarına dönüştürebileceğimiz bir dizi tahmin olasılığı elde ederiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVUutKhQP9Xl",
    "outputId": "f7f9855b-1524-427a-fef1-1bc55c6ab683"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HZvJ3GxQKxs"
   },
   "source": [
    "Şimdi tahmini sınıflarımız var, bunları temel doğruluk etiketlerine göre değerlendirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKmZyOQ7QEBH",
    "outputId": "53fd50bd-9731-420a-b08f-bfd9b0c196cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.34645669291339,\n",
       " 'f1': 0.7814394387142286,\n",
       " 'precision': 0.7855568462558434,\n",
       " 'recall': 0.7834645669291339}"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i2wwm8QQREo"
   },
   "source": [
    "Son olarak, GRU modelimizin sonuçlarını taban çizgimizle karşılaştırabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jk5_c8T3QN0j",
    "outputId": "bf77efae-f18e-40c0-d165-cfa6db1e8c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.35, Difference: -0.92\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzP4ZSLmQrIM"
   },
   "source": [
    "## Model 4: Çift Yönlü RNN modeli\n",
    "\n",
    "Halihazırda GRU ve LSTM hücreli iki RNN oluşturduk. Şimdi başka bir tür RNN'yi, çift yönlü RNN'yi inceleyeceğiz.\n",
    "\n",
    "Standart bir RNN, bir diziyi soldan sağa işleyecektir, burada çift yönlü bir RNN, diziyi soldan sağa ve ardından tekrar sağdan sola işleyecektir.\n",
    "\n",
    "Sezgisel olarak, bu, bir cümleyi ilk kez normal şekilde (soldan sağa) okuyormuşsunuz gibi düşünülebilir, ancak bir nedenden dolayı bu mantıklı gelmedi, bu yüzden kelimeler arasında geri dönüp tekrar üzerinden geçtiniz. (sağdan sola).\n",
    "\n",
    "Pratikte, birçok dizi modeli, çift yönlü RNN'leri kullanırken performansta sıklıkla görülür ve gelişme gösterir.\n",
    "\n",
    "Bununla birlikte, performanstaki bu gelişme genellikle daha uzun eğitim süreleri ve artan model parametreleri pahasına gelir (model soldan sağa ve sağdan sola gittiğinden, eğitilebilir parametrelerin sayısı iki katına çıkar).\n",
    "\n",
    "Yeterince konuştuk, hadi çift yönlü bir RNN oluşturalım.\n",
    "\n",
    "TensorFlow bir kez daha [`tensorflow.keras.layers.Bi Directional`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bi Direction) sınıfını sağlayarak bize yardımcı oluyor. Mevcut RNN'lerimizi sarmak için `Bi Directional` sınıfını kullanabilir ve onları anında çift yönlü hale getirebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Fu4y6IIZQSGR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "\n",
    "# çift yönlü, her iki yöne de gider, \n",
    "# bu nedenle normal bir LSTM katmanının parametrelerinin iki katıdır\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXcY9TkdRMK5"
   },
   "source": [
    "> 🔑 **Not:** TensorFlow'daki herhangi bir RNN hücresinde \"Çift Yönlü\" sarmalayıcıyı kullanabilirsiniz. Örneğin, `layers.Bidirectional(layers.GRU(64))` çift yönlü bir GRU hücresi oluşturur.\n",
    "\n",
    "Çift yönlü modelimiz oluşturuldu, derleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PW6ma0xRQyFC",
    "outputId": "839bf4d7-b6cd-4c00-dde0-459a7fe411f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORNxnaZ8RVvl"
   },
   "source": [
    "model_2'ye (normal LSTM) kıyasla model_4'te (çift yönlü LSTM) artan eğitilebilir parametre sayısına dikkat edin. Bunun nedeni, RNN'mize eklediğimiz çift yönlülüktür.\n",
    "\n",
    "Çift yönlü modelimize fit etme ve performansını takip etme zamanı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3K0xsPXMRS3c",
    "outputId": "79246b39-7e67-4a4b-f439-23e8894f36cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210801-153806\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 8s 26ms/step - loss: 0.1109 - accuracy: 0.9663 - val_loss: 0.9836 - val_accuracy: 0.7703\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0510 - accuracy: 0.9780 - val_loss: 1.2340 - val_accuracy: 0.7795\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0450 - accuracy: 0.9803 - val_loss: 1.1361 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0434 - accuracy: 0.9793 - val_loss: 1.3135 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0386 - accuracy: 0.9820 - val_loss: 1.4744 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "model_4_history = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERa3QI77RhJF"
   },
   "source": [
    "Modelimizin çift yönlü olması nedeniyle eğitim süresinde hafif bir artış görüyoruz. Endişelenme, çok dramatik bir artış değil. Onunla bazı tahminler yapalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pq9H6Eb_Reti",
    "outputId": "19c6f089-b098-4a3f-d768-39e1a999ce68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4356615e-04],\n",
       "       [8.4144211e-01],\n",
       "       [9.9998629e-01],\n",
       "       [2.4504794e-02],\n",
       "       [4.6845675e-05],\n",
       "       [9.9975747e-01],\n",
       "       [9.9537474e-01],\n",
       "       [9.9999297e-01],\n",
       "       [9.9998868e-01],\n",
       "       [9.9848819e-01]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBRbqlJgRmeX"
   },
   "source": [
    "Ve onları tahmin sınıflarına dönüştüreceğiz ve onları temel doğruluk etiketlerine ve temel modele göre değerlendireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FXiAft6Rkbj",
    "outputId": "94ede789-c09f-4875-9d46-f6cd6145c63a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Tahmin olasılıklarını etiketlere dönüştürün\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZ0jJGNoRpjh",
    "outputId": "8b161359-0524-4634-ba78-b02b44cce1d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'f1': 0.7722311836526509,\n",
       " 'precision': 0.7759894665484696,\n",
       " 'recall': 0.7742782152230971}"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Çift yönlü RNN model sonuçlarını hesaplayın\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWM0eE6zRxzO",
    "outputId": "4d83e995-be80-43e7-dce4-56e14d58748e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.43, Difference: -1.84\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Çift yönlü modelin taban çizgisine göre nasıl \n",
    "# performans gösterdiğini kontrol edin\n",
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IeuFSzmSVIl"
   },
   "source": [
    "## Metin için Evrişimli Sinir Ağları\n",
    "\n",
    "Daha önce görüntüler için evrişimli sinir ağlarını (CNN'ler) kullanmış olabilirsiniz, ancak bunlar diziler için de kullanılabilir.\n",
    "\n",
    "Görüntüler ve diziler için CNN'leri kullanma arasındaki temel fark, verilerin şeklidir. Görüntüler 2 boyutlu (yükseklik x genişlik) gelirken, diziler genellikle 1 boyutludur (bir metin dizisi).\n",
    "\n",
    "CNN'leri dizilerle kullanmak için 2 boyutlu evrişim yerine 1 boyutlu evrişim kullanırız.\n",
    "\n",
    "Diziler için tipik bir CNN mimarisi aşağıdaki gibi görünecektir:\n",
    "\n",
    "```\n",
    "Girdiler (metin) -> Simgeleştirme -> Gömme -> Katmanlar -> Çıktılar (sınıf olasılıkları)\n",
    "```\n",
    "\n",
    "\"Bu, diğer modeller için kullandığımız mimari düzene benziyor...\" diye düşünüyor olabilirsiniz. Haklısınız da. Fark yine katmanlar bileşenindedir. Bir LSTM veya GRU hücresi kullanmak yerine, bir [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/) kullanacağız Conv1D) katmanı ve ardından bir [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) katmanı."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrLS7JFPSkbw"
   },
   "source": [
    "## Model 5: Conv1D\n",
    "\n",
    "Tam 1 boyutlu bir CNN modeli oluşturmadan önce, 1 boyutlu evrişim katmanını (**zamansal evrişim** olarak da adlandırılır) çalışırken görelim. Önce bir metin örneğinin gömülmesini oluşturacağız ve onu bir `Conv1D()` katmanı ve `GlobalMaxPool1D()` katmanından geçirmeyi deneyeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ByxVuFER4n1",
    "outputId": "cfc6a8fb-9c24-4221-ae43-612dfee5a67f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
    "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")\n",
    "conv_1d_output = conv_1d(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D() \n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDB9Qjh_S55S"
   },
   "source": [
    "Her katmanın çıktı şekillerine dikkat edin.\n",
    "\n",
    "Gömme, ayarladığımız parametrelerin çıktı şekli boyutuna sahiptir (`input_length=15` ve`output_dim=128`).\n",
    "\n",
    "1 boyutlu evrişim katmanı, parametreleriyle aynı hizada sıkıştırılmış bir çıktıya sahiptir. Aynı şey, maksimum havuzlama katmanı çıktısı için de geçerlidir.\n",
    "\n",
    "Metnimiz bir dize olarak başlar, ancak çeşitli dönüştürme adımlarıyla (belirteçleştirmeden yerleştirmeye, 1 boyutlu evrişimden maksimum havuza) 64 uzunluğunda bir özellik vektörüne dönüştürülür. Bu dönüşümlerin her birinin neye benzediğine bir bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0DjFrzwSyKP",
    "outputId": "1a30872c-171b-4f0d-f961-e80dfb034b29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       " array([[[ 0.07935887,  0.00606174, -0.02900355, ...,  0.02563756,\n",
       "          -0.01159754,  0.0028156 ],\n",
       "         [-0.07162038, -0.00598791,  0.04549426, ..., -0.0096315 ,\n",
       "           0.02526558,  0.01819799],\n",
       "         [-0.01358257, -0.07636132, -0.01914257, ...,  0.05432836,\n",
       "           0.02298414,  0.02955275],\n",
       "         ...,\n",
       "         [ 0.00397736, -0.02623309,  0.01196784, ...,  0.00215693,\n",
       "           0.0066976 ,  0.0234192 ],\n",
       "         [ 0.00397736, -0.02623309,  0.01196784, ...,  0.00215693,\n",
       "           0.0066976 ,  0.0234192 ],\n",
       "         [ 0.00397736, -0.02623309,  0.01196784, ...,  0.00215693,\n",
       "           0.0066976 ,  0.0234192 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
       " array([[[0.        , 0.05690441, 0.05285177, 0.        , 0.0180884 ,\n",
       "          0.02882726, 0.04080626, 0.        , 0.00148557, 0.02165018,\n",
       "          0.        , 0.        , 0.06295198, 0.        , 0.04039711,\n",
       "          0.        , 0.05721434, 0.06057747, 0.0626595 , 0.02074664,\n",
       "          0.        , 0.05778538, 0.05920956, 0.01130978, 0.        ,\n",
       "          0.        , 0.        , 0.00420184, 0.        , 0.        ,\n",
       "          0.00469104, 0.        ],\n",
       "         [0.01333249, 0.01023622, 0.00460276, 0.        , 0.01757135,\n",
       "          0.01829607, 0.        , 0.0262695 , 0.        , 0.02639193,\n",
       "          0.        , 0.02588441, 0.        , 0.        , 0.03884322,\n",
       "          0.02489556, 0.02860131, 0.        , 0.00422521, 0.0331399 ,\n",
       "          0.        , 0.        , 0.        , 0.04131615, 0.04867007,\n",
       "          0.        , 0.        , 0.10718557, 0.        , 0.00798158,\n",
       "          0.00821742, 0.        ],\n",
       "         [0.        , 0.03445299, 0.04340572, 0.05354061, 0.02494319,\n",
       "          0.        , 0.        , 0.        , 0.06803069, 0.0300979 ,\n",
       "          0.        , 0.        , 0.08175348, 0.        , 0.00450628,\n",
       "          0.01824   , 0.04239858, 0.03069189, 0.07114986, 0.00635919,\n",
       "          0.        , 0.        , 0.        , 0.07567331, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.06562802,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.05272358, 0.04586241, 0.        ,\n",
       "          0.        , 0.0226765 , 0.00967824, 0.        , 0.01657301,\n",
       "          0.00333301, 0.        , 0.        , 0.        , 0.03598679,\n",
       "          0.07951859, 0.        , 0.03343596, 0.03662868, 0.0268628 ,\n",
       "          0.0113782 , 0.        , 0.        , 0.02937523, 0.        ,\n",
       "          0.0043251 , 0.02814908, 0.03041438, 0.        , 0.        ,\n",
       "          0.009555  , 0.01047972],\n",
       "         [0.        , 0.01732019, 0.04570982, 0.02897843, 0.        ,\n",
       "          0.        , 0.03221568, 0.03426346, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.0614885 ,\n",
       "          0.02594871, 0.        , 0.03443816, 0.03737513, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.02973526, 0.04856867,\n",
       "          0.        , 0.02295054, 0.        , 0.00226113, 0.01191485,\n",
       "          0.04680892, 0.        ],\n",
       "         [0.        , 0.02282062, 0.00528565, 0.00618665, 0.00781008,\n",
       "          0.        , 0.01120787, 0.01631753, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03385198, 0.01994631, 0.03618488, 0.03873807, 0.00636665,\n",
       "          0.        , 0.01566767, 0.        , 0.03648477, 0.00926591,\n",
       "          0.        , 0.        , 0.        , 0.03317049, 0.01300492,\n",
       "          0.01469289, 0.03873161],\n",
       "         [0.        , 0.02282062, 0.00528565, 0.00618665, 0.00781008,\n",
       "          0.        , 0.01120788, 0.01631753, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03385197, 0.01994631, 0.03618488, 0.03873807, 0.00636664,\n",
       "          0.        , 0.01566769, 0.        , 0.03648478, 0.0092659 ,\n",
       "          0.        , 0.        , 0.        , 0.03317049, 0.01300493,\n",
       "          0.0146929 , 0.03873161],\n",
       "         [0.        , 0.02282062, 0.00528565, 0.00618665, 0.00781008,\n",
       "          0.        , 0.01120787, 0.01631753, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03385198, 0.01994631, 0.03618487, 0.03873807, 0.00636665,\n",
       "          0.        , 0.01566768, 0.        , 0.03648477, 0.00926591,\n",
       "          0.        , 0.        , 0.        , 0.03317049, 0.01300492,\n",
       "          0.0146929 , 0.03873161],\n",
       "         [0.        , 0.02282062, 0.00528565, 0.00618664, 0.00781008,\n",
       "          0.        , 0.01120788, 0.01631753, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03385197, 0.01994631, 0.03618488, 0.03873807, 0.00636664,\n",
       "          0.        , 0.01566768, 0.        , 0.03648477, 0.0092659 ,\n",
       "          0.        , 0.        , 0.        , 0.0331705 , 0.01300491,\n",
       "          0.0146929 , 0.03873162],\n",
       "         [0.        , 0.02282062, 0.00528564, 0.00618664, 0.00781008,\n",
       "          0.        , 0.01120787, 0.01631753, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03385197, 0.01994632, 0.03618488, 0.03873806, 0.00636664,\n",
       "          0.        , 0.01566768, 0.        , 0.03648477, 0.00926591,\n",
       "          0.        , 0.        , 0.        , 0.03317049, 0.01300492,\n",
       "          0.01469289, 0.03873161],\n",
       "         [0.        , 0.02282062, 0.00528565, 0.00618664, 0.00781008,\n",
       "          0.        , 0.01120788, 0.01631752, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03385197, 0.01994631, 0.03618488, 0.03873807, 0.00636664,\n",
       "          0.        , 0.01566768, 0.        , 0.03648477, 0.0092659 ,\n",
       "          0.        , 0.        , 0.        , 0.0331705 , 0.01300492,\n",
       "          0.01469289, 0.03873161]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[0.01333249, 0.05690441, 0.05285177, 0.05354061, 0.02494319,\n",
       "         0.02882726, 0.04080626, 0.03426346, 0.06803069, 0.0300979 ,\n",
       "         0.00333301, 0.02588441, 0.08175348, 0.        , 0.0614885 ,\n",
       "         0.07951859, 0.05721434, 0.06057747, 0.07114986, 0.0331399 ,\n",
       "         0.0113782 , 0.05778538, 0.05920956, 0.07567331, 0.04867007,\n",
       "         0.0043251 , 0.02814908, 0.10718557, 0.0331705 , 0.06562802,\n",
       "         0.04680892, 0.03873162]], dtype=float32)>)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n6JTzXmTKZ9"
   },
   "source": [
    "Pekala, diziler için bir CNN'nin çeşitli bileşenlerinin çıktılarını gördük, onları bir araya getirelim ve tam bir model oluşturalım, onu derleyelim (tıpkı diğer modellerimizde yaptığımız gibi) ve bir özet alalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4G8NDm1lTFwY",
    "outputId": "c01ae5cb-1c69-4174-f801-1834a34bdada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b92WMr-dTWFs"
   },
   "source": [
    "Süperr! Harika görünüyor! 1-boyutlu evrişimli katman için eğitilebilir parametre sayısının `model_2`'deki LSTM katmanınınkine nasıl benzer olduğuna dikkat edin.\n",
    "\n",
    "1D CNN modelimizi metin verilerimizle fit edelim. Önceki deneylere uygun olarak, `create_tensorboard_callback()` fonksiyonumuzu kullanarak sonuçlarını kaydedeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4APDHWOTQNO",
    "outputId": "f4bda713-0b83-464e-a166-7cb7d844dd69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20210801-153855\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 20ms/step - loss: 0.1315 - accuracy: 0.9603 - val_loss: 0.8737 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0777 - accuracy: 0.9721 - val_loss: 0.9853 - val_accuracy: 0.7677\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0613 - accuracy: 0.9769 - val_loss: 1.1187 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0548 - accuracy: 0.9781 - val_loss: 1.1937 - val_accuracy: 0.7638\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0527 - accuracy: 0.9787 - val_loss: 1.2281 - val_accuracy: 0.7690\n"
     ]
    }
   ],
   "source": [
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"Conv1D\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctGeP3naTj2d"
   },
   "source": [
    "Güzel! GPU hızlandırma sayesinde 1D evrişimli modelimiz güzel ve hızlı bir şekilde eğitiyor. Onunla bazı tahminler yapalım ve eskisi gibi değerlendirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAWzo-fTTg6Y",
    "outputId": "86d6e447-44de-40d5-ce02-4239d640540d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5966418e-01],\n",
       "       [7.7939183e-01],\n",
       "       [9.9991620e-01],\n",
       "       [4.4257466e-02],\n",
       "       [2.8306598e-08],\n",
       "       [9.8507363e-01],\n",
       "       [9.6121919e-01],\n",
       "       [9.9981207e-01],\n",
       "       [9.9999893e-01],\n",
       "       [7.4319720e-01]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7vLZloeTpS3",
    "outputId": "936b74d2-fdf4-4b31-b3bb-6f8a490c9c73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbP9T7i9TrfX",
    "outputId": "ab3e0145-4b48-459a-918c-35bd60ccbe87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.9028871391076,\n",
       " 'f1': 0.7669342344352704,\n",
       " 'precision': 0.7706028054440214,\n",
       " 'recall': 0.7690288713910761}"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zN_e-ar-TsgW",
    "outputId": "5d9fe88b-870b-4512-9c9c-d1d8260a6977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.90, Difference: -2.36\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZYzwJTwT0Ms"
   },
   "source": [
    "# Önceden Eğitilmiş Gömmeleri Kullanma (NLP için transfer öğrenimi)\n",
    "\n",
    "Oluşturduğumuz ve eğittiğimiz önceki tüm derin öğrenme modelleri için her seferinde sıfırdan kendi yerleştirmelerimizi oluşturduk ve kullandık.\n",
    "\n",
    "Ancak yaygın bir uygulama, **aktarım öğrenimi** aracılığıyla önceden eğitilmiş yerleştirmelerden yararlanmaktır. Bir sonraki modelimiz için, kendi gömme katmanımızı kullanmak yerine, onu önceden eğitilmiş bir gömme katmanıyla değiştireceğiz.\n",
    "\n",
    "Daha spesifik olarak, [TensorFlow Hub](https://tfhub.dev/google) adresinden [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) kullanacağız. (universal-sentence-encoder, çeşitli görevler için çok sayıda önceden eğitilmiş model kaynağı içeren harika bir model).\n",
    "\n",
    "> 🔑 **Not:** TensorFlow Hub'da önceden eğitilmiş birçok farklı metin gömme seçeneği vardır, ancak bazıları diğerlerinden farklı seviyelerde metin ön işleme gerektirir. Birkaçını denemek ve kullanım durumunuza en uygun olanı görmek en iyisidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHSjjv3CXuAj"
   },
   "source": [
    "## Model 6: TensorFlow Hub Önceden Eğitilmiş Cümle Kodlayıcı\n",
    "\n",
    "Oluşturduğumuz gömme katmanı ile Evrensel Cümle Kodlayıcı arasındaki temel fark, tahmin edebileceğiniz gibi, Evrensel Cümle Kodlayıcı'nın sözcük düzeyinde bir gömme oluşturmak yerine, tam bir cümle düzeyinde gömme oluşturmasıdır.\n",
    "\n",
    "Gömme katmanımız ayrıca her kelime için 128 boyutlu bir vektör üretirken, Evrensel Cümle Kodlayıcı her cümle için 512 boyutlu bir vektör verir.\n",
    "\n",
    "> 🔑 **Not:** Bir **encoder**, metin gibi ham verileri sayısal bir gösterime (özellik vektörü) dönüştüren bir modelin adıdır, bir **decoder** sayısal gösterimi istenen bir çıktıya dönüştürür .\n",
    "\n",
    "Her zamanki gibi, bu en iyi bir örnekle gösterilir. Universal (evrensel) Cümle Kodlayıcı modelini yükleyelim ve birkaç cümle üzerinde test edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBLqQLV3Xtsb",
    "outputId": "e1a4547d-ccf8-41ab-aae4-685cc828d573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
      "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
      "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
      "  0.00991367 -0.06865346 -0.04209305  0.0267898   0.03011008  0.00321069\n",
      " -0.00337971 -0.04787356  0.02266719 -0.00985925 -0.04063613 -0.01292093\n",
      " -0.04666384  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014441\n",
      "  0.02871508  0.04947684 -0.00633978 -0.08960193  0.02807117 -0.00808362\n",
      " -0.01360601  0.0599865  -0.10361787 -0.05195374  0.00232955 -0.0233253\n",
      " -0.03758105  0.03327729], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# Evrensel Cümle Kodlayıcıyı yükle\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") \n",
    "embed_samples = embed([sample_sentence,\n",
    "                       \"When you call the universal sentence encoder \\\n",
    "                       on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYLrrlJAcahN",
    "outputId": "50198d3e-cf72-4ecb-a9e8-8bda76889290"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Her cümle 512 boyutlu bir vektöre kodlanmıştır\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf9HuS8qc2zn"
   },
   "source": [
    "Cümlelerimizi Evrensel Cümle Kodlayıcıya (USE) geçirmek, onları dizelerden 512 boyutlu vektörlere kodlar; bu bizim için hiçbir anlam ifade etmez, ancak umarım makine öğrenimi modellerimiz için bir anlam ifade eder.\n",
    "\n",
    "Modellerden bahsetmişken, gömme katmanımız olarak USE ile bir tane oluşturalım.\n",
    "\n",
    "[`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) sınıfını kullanarak TensorFlow Hub USE modülünü Keras katmanına dönüştürebiliriz.\n",
    "\n",
    "> 🔑 **Not:** TensorFlow Hub'ı KULLAN modülünün boyutu nedeniyle, indirilmesi biraz zaman alabilir. Yine de indirildikten sonra önbelleğe alınacak ve kullanıma hazır olacaktır. Ve birçok TensorFlow Hub modülünde olduğu gibi, USE'nin daha az yer kaplayan ancak performanstan biraz ödün veren bir [\"lite\" sürümü](https://tfhub.dev/google/universal-sentence-encoder-lite/2) vardır. ve daha fazla ön işleme adımı gerektirir. Ancak, mevcut işlem gücünüze bağlı olarak, uygulama kullanım durumunuz için lite sürümü daha iyi olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "j6sFgOQLceGI"
   },
   "outputs": [],
   "source": [
    "# Bu kodlama katmanını text_vectorizer ve gömme katmanımız yerine kullanabiliriz\n",
    "sentence_encoder_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    input_shape=[], # modelimize gelen girdilerin şekli\n",
    "    dtype=tf.string, # USE katmanına gelen veri tipi girdiler\n",
    "    trainable=False, # önceden eğitilmiş ağırlıkları koru\n",
    "    name=\"USE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLSDMbiCdVhr"
   },
   "source": [
    "Güzel! Şimdi Keras katmanı olarak USE'ye sahibiz, onu Keras Sıralı modelinde kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoXe94E6dQwO",
    "outputId": "db36bebd-5e71-49e0-acc9-1ccf82faf330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE (KerasLayer)             (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer,\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# modeli derleme\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aw2zaIKedq9P"
   },
   "source": [
    "USE katmanındaki parametrelerin sayısına dikkat edin, bunlar çeşitli metin kaynaklarında (Wikipedia, web haberleri, web soru-cevap forumları vb.) öğrendiği önceden eğitilmiş ağırlıklardır.\n",
    "\n",
    "Eğitilebilir parametreler yalnızca çıktı katmanlarımızdadır, başka bir deyişle, USE ağırlıklarını donmuş halde tutuyor ve onu bir özellik çıkarıcı olarak kullanıyoruz. \"hub.KerasLayer\" örneğini oluştururken \"trainable=True\" ayarını yaparak bu ağırlıklara ince ayar yapabiliriz.\n",
    "\n",
    "Şimdi hazır bir özellik çıkarıcı modelimiz var, hadi onu eğitelim ve `create_tensorboard_callback()` fonksiyonumuzu kullanarak sonuçlarını TensorBoard'a izleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47ZR0OxSdfqR",
    "outputId": "8dcdc468-7e52-4510-b5bf-575696345b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210801-160624\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 24ms/step - loss: 0.5072 - accuracy: 0.7825 - val_loss: 0.4490 - val_accuracy: 0.8005\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4148 - accuracy: 0.8178 - val_loss: 0.4403 - val_accuracy: 0.8123\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 0.4014 - accuracy: 0.8235 - val_loss: 0.4349 - val_accuracy: 0.8123\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3932 - accuracy: 0.8257 - val_loss: 0.4319 - val_accuracy: 0.8110\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3859 - accuracy: 0.8318 - val_loss: 0.4258 - val_accuracy: 0.8176\n"
     ]
    }
   ],
   "source": [
    "model_6_history = model_6.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvT_VUXik8xT"
   },
   "source": [
    "Diğer modellerimizde yaptığımız gibi onunla da bazı tahminler yapalım ve onları değerlendirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgC0BVTFd2HS",
    "outputId": "d2e35210-1f0e-42a1-fc5e-e3658025fb31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21114992],\n",
       "       [0.8244935 ],\n",
       "       [0.9867014 ],\n",
       "       [0.23293671],\n",
       "       [0.77170694],\n",
       "       [0.7586733 ],\n",
       "       [0.97968525],\n",
       "       [0.98227775],\n",
       "       [0.9455673 ],\n",
       "       [0.10212851]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USE TF Hub modeli ile tahminler yapın\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qA5ppVXvk66-",
    "outputId": "7d161fad-2123-4a76-ba5c-629727991567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tahmin olasılıklarını etiketlere dönüştürün\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-LhnO-ulK1f",
    "outputId": "f4d89f09-9ea9-43b5-be2c-e4fcfe0b6eff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.75853018372703,\n",
       " 'f1': 0.8169333236783015,\n",
       " 'precision': 0.8177933628741751,\n",
       " 'recall': 0.8175853018372703}"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 6 performans metriklerini hesaplayın\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYuerDLPlOd2",
    "outputId": "5beb5fe6-435e-4607-c5e2-273701f227ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 81.76, Difference: 2.49\n",
      "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
      "Baseline recall: 0.79, New recall: 0.82, Difference: 0.02\n",
      "Baseline f1: 0.79, New f1: 0.82, Difference: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Karşılaştırma\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRaqVxxElzWr"
   },
   "source": [
    "## Model 7\n",
    "\n",
    "USE içindeki önceden eğitilmiş yerleştirmeler gibi transfer öğrenme yöntemlerini kullanmanın faydalarından biri, az miktarda veri üzerinde harika sonuçlar elde etme yeteneğidir (USE makalesi özette bundan bahseder).\n",
    "\n",
    "Bunu test etmek için, eğitim verilerinin küçük bir alt kümesini (%10) oluşturacağız, bir model eğiteceğiz ve onu değerlendireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW3llpawlTjn",
    "outputId": "1023344f-a223-4298-a620-f0aacd3c5158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 6851\n",
      "Length of 10% training examples: 686\n"
     ]
    }
   ],
   "source": [
    "train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
    "len(train_sentences_10_percent), len(train_labels_10_percent)\n",
    "\n",
    "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
    "                                                                                                                            train_labels,\n",
    "                                                                                                                            test_size=0.1,\n",
    "                                                                                                                            random_state=42)\n",
    "print(f\"Total training examples: {len(train_sentences)}\")\n",
    "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9vrjy7xmYdc"
   },
   "source": [
    "Eğitim örneklerinin rastgele bir alt kümesini seçtiğimiz için, sınıfların kabaca dengelenmesi gerekir (tam eğitim veri kümesinde olduğu gibi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2rk6SoKmFvX",
    "outputId": "d7aaadfb-11d0-4f5d-8654-968defde6ff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    415\n",
       "1    271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veri alt kümemizdeki hedef sayısını kontrol edin\n",
    "# (bu, orijinal train_labels içindeki etiketlerin dağılımına yakın olmalıdır)\n",
    "pd.Series(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn8FsVaLmkT4"
   },
   "source": [
    "Modelimizin tam eğitim kümesinden öğrenme yeteneği ile %10 alt kümeden öğrenme yeteneği arasında uygun bir karşılaştırma yaptığımızdan emin olmak için, [`tf.keras.models.clone_model()` kullanarak USE modelimizi (\"model_6\") kullanarak klonlayacağız.`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model)\n",
    "\n",
    "Bunu yapmak aynı mimariyi yaratacak ancak klon hedefinin öğrenilen ağırlıklarını sıfırlayacaktır (USE'den gelen önceden eğitilmiş ağırlıklar kalacak, ancak diğerleri sıfırlanacaktır)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m6eDlAsmeGy",
    "outputId": "27affd83-da94-49ae-ca88-70d7e22a5e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE (KerasLayer)             (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npZw9sCWm6sL"
   },
   "source": [
    "`model_7` düzeninin `model_6` ile aynı olduğuna dikkat edin. Şimdi yeni oluşturulan modeli %10 eğitim verisi alt kümemizde eğitelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4sP_Dwum3iQ",
    "outputId": "e8a134c7-e437-4cc8-df32-ee7c4113d7d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210801-164936\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 120ms/step - loss: 0.6725 - accuracy: 0.6531 - val_loss: 0.6481 - val_accuracy: 0.7362\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5974 - accuracy: 0.8192 - val_loss: 0.5894 - val_accuracy: 0.7625\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5181 - accuracy: 0.8236 - val_loss: 0.5348 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4551 - accuracy: 0.8294 - val_loss: 0.5033 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4097 - accuracy: 0.8280 - val_loss: 0.4943 - val_accuracy: 0.7651\n"
     ]
    }
   ],
   "source": [
    "model_7_history = model_7.fit(\n",
    "    x=train_sentences_10_percent,\n",
    "    y=train_labels_10_percent,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f0HCRNsn1rE"
   },
   "source": [
    "Daha az miktarda eğitim verisi nedeniyle eğitim, eskisinden daha hızlı bitti. Eğitim verilerinin %10'unu öğrendikten sonra modelimizin performansını değerlendirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_L7lsGSnvCm",
    "outputId": "f97c8619-18ab-4c67-81d6-4c0e928a3599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24823202],\n",
       "       [0.77385026],\n",
       "       [0.90565777],\n",
       "       [0.31064412],\n",
       "       [0.48999107],\n",
       "       [0.8384433 ],\n",
       "       [0.8271982 ],\n",
       "       [0.8706751 ],\n",
       "       [0.8083445 ],\n",
       "       [0.12355509]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJMAmakcn6Hb",
    "outputId": "e9ce8da5-b1e5-4653-fd34-6cd78a3d2f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GE1hgSC6n7PE",
    "outputId": "f6d8d989-5dcc-45d0-9dc1-134a6626297e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.50918635170603,\n",
       " 'f1': 0.7596870346821398,\n",
       " 'precision': 0.7746651651856151,\n",
       " 'recall': 0.7650918635170604}"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "440VQNrin8y6",
    "outputId": "ada9fd0d-9bb6-4ef6-c2d1-4743dd1f0b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.51, Difference: -2.76\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
     ]
    }
   ],
   "source": [
    "compare_baseline_to_new_results(baseline_results, model_7_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLoCw93kow2V"
   },
   "source": [
    "# Modellerimizin Her Birinin Performansını Karşılaştırma\n",
    "\n",
    "Şimdi modelimizin sonuçlarını karşılaştırma zamanı. Ancak bundan hemen önce, bu tür bir uygulamanın standart bir derin öğrenme iş akışı olduğunu belirtmekte fayda var. Çeşitli farklı modelleri eğitin, ardından hangisinin en iyi performansı gösterdiğini görmek için bunları karşılaştırın ve gerekirse onu eğitmeye devam edin.\n",
    "\n",
    "Unutulmaması gereken önemli nokta, tüm modelleme deneylerimiz için aynı eğitim verilerini kullandığımızdır (eğitim verilerinin %10'unu kullandığımız 'model_7' hariç).\n",
    "\n",
    "Modelimizin performanslarını görselleştirmek için, result sözlüklerimiz olan bir pandas DataFrame oluşturalım ve sonra onu çizelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "hz8aFLpnn-D-",
    "outputId": "6ec747af-7176-43fe-bb2b-0b4c75d4689e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>78.215223</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.782152</td>\n",
       "      <td>0.779088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>0.778385</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.778288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>78.346457</td>\n",
       "      <td>0.785557</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.781439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>77.427822</td>\n",
       "      <td>0.775989</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.772231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>76.902887</td>\n",
       "      <td>0.770603</td>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.766934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>81.758530</td>\n",
       "      <td>0.817793</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.816933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>76.509186</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>0.765092</td>\n",
       "      <td>0.759687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 79.265092   0.811139  0.792651  0.786219\n",
       "simple_dense             78.215223   0.786845  0.782152  0.779088\n",
       "lstm                     77.821522   0.778385  0.778215  0.778288\n",
       "gru                      78.346457   0.785557  0.783465  0.781439\n",
       "bidirectional            77.427822   0.775989  0.774278  0.772231\n",
       "conv1d                   76.902887   0.770603  0.769029  0.766934\n",
       "tf_hub_sentence_encoder  81.758530   0.817793  0.817585  0.816933\n",
       "tf_hub_10_percent_data   76.509186   0.774665  0.765092  0.759687"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"gru\": model_3_results,\n",
    "                                  \"bidirectional\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
    "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "7L-3jzSLo48S",
    "outputId": "d7251aa4-a181-4be2-eba3-9883351f9b31"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Doğruluğu diğer metriklerle aynı ölçeğe indirin\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSxAy8c5pN3T"
   },
   "source": [
    "Önceden eğitilmiş USE TensorFlow Hub modellerimiz en iyi performansa sahip gibi görünüyor, eğitim verilerinin yalnızca %10'una sahip olan model bile diğer modellerden daha iyi performans gösteriyor. Bu, transfer öğrenmenin gücünü gösterir.\n",
    "\n",
    "Detaylara inip her modelin F1 puanlarını almaya ne dersiniz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "LU4uN7i7o9pf",
    "outputId": "9631212d-69e1-487e-9ee1-011d72dbcc84"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yLDXDttpRax"
   },
   "source": [
    "Tek bir ölçümde detaya indiğimizde, USE TensorFlow Hub modellerimizin diğer tüm modellerden daha iyi performans gösterdiğini görüyoruz. İlginç bir şekilde, temelin F1 puanı, daha derin modellerin geri kalanından çok uzakta değil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfTTMvYdrVby"
   },
   "source": [
    "## Modellerimizi Birleştirmek\n",
    "\n",
    "Birçok üretim sistemi, bir tahmin yapmak için bir **ensemble** (birden çok farklı modelin bir araya getirilmesi) modellerini kullanır.\n",
    "\n",
    "Model istiflemenin ardındaki fikir, birbiriyle ilişkisiz birkaç modelin bir tahmin üzerinde anlaşmaya varması durumunda, tahminin tekil bir model tarafından yapılan bir tahminden daha sağlam olması gerektiğidir.\n",
    "\n",
    "Yukarıdaki cümledeki anahtar kelime ** uncorrelated**, bu da farklı model türleri demenin başka bir yoludur. Örneğin, bizim durumumuzda taban çizgimizi, çift yönlü modelimizi ve TensorFlow Hub USE modelimizi birleştirebiliriz.\n",
    "\n",
    "Bu modellerin hepsi aynı veriler üzerinde eğitilmiş olsa da, hepsinin farklı bir kalıp bulma yolu vardır.\n",
    "\n",
    "Üç LSTM modeli gibi benzer şekilde eğitilmiş üç model kullanacak olsaydık, çıktı tahminleri muhtemelen çok benzer olacaktır.\n",
    "\n",
    "Bunu arkadaşlarınızla nerede yemek yiyeceğinize karar vermeye çalışmak olarak düşünün. Hepinizin zevkleri benzerse, muhtemelen hepiniz aynı restoranı seçeceksiniz. Ama hepinizin farklı zevkleri varsa ve yine de aynı restoranı seçerseniz, restoran iyi olmalı.\n",
    "\n",
    "Bir sınıflandırma problemi ile çalıştığımız için modellerimizi birleştirmenin birkaç yolu vardır:\n",
    "1. **Ortalama** - Her örnek için her modelin çıktı tahmin olasılıklarını alın, birleştirin ve ardından ortalamasını alın.\n",
    "2. **Çoğunluk oyu (mod)** - Modellerinizin her biri ile tüm örneklerde sınıf tahminleri yapın, tahmin edilen sınıf çoğunlukta olandır. Örneğin, üç farklı model sırasıyla `[1, 0, 1]` değerini tahmin ederse, çoğunluk sınıfı `1` olur, bu nedenle bu tahmin edilen etiket olacaktır.\n",
    "3. **Model yığınlama** - Seçtiğiniz modellerin her birinin çıktılarını alın ve bunları başka bir modele girdi olarak kullanın.\n",
    "\n",
    "> 📖 **Kaynak:** Model istifleme/birleştirme için yukarıdaki yöntemler, Andriy Burkov tarafından [Machine Learning Engineering Book](http://www.mlebook.com/wiki/doku.php) Bölüm 6'dan uyarlanmıştır. Makine öğrenimi mühendisliği alanına girmek, yalnızca modeller oluşturmak değil, aynı zamanda üretim ölçeğinde makine öğrenimi sistemleri kurmak istiyorsanız, tamamını okumanızı şiddetle tavsiye ederim.\n",
    "\n",
    "Yine, model istifleme kavramı en iyi eylemde görülür.\n",
    "\n",
    "Temel modelimizi (`model_0`), LSTM modelimizi (`model_2`) ve tam eğitim verisi (`model_6`) üzerinde eğitilmiş USE modelimizi, her birinin birleşik tahmin olasılıklarının ortalamasını alarak birleştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXPcMqjFpO8I",
    "outputId": "9b1d283e-4950-4ac4-a176-e8ca7f00f645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temel modelden tahmin olasılıklarını alın\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1)\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "# tahmin sınıfları için olasılıklarını ortalamasını alın ve yuvarlayın\n",
    "combined_preds = tf.round(combined_pred_probs/3)\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WyRqTSGtKFd"
   },
   "source": [
    "Olağanüstü! Farklı sınıflardan oluşan birleştirilmiş bir tahminler dizimiz var, bunları gerçek etiketlere göre değerlendirelim ve yığılmış modelimizin sonuçlarını `all_model_results` DataFrame'imize ekleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wG6-h3-ds4YN",
    "outputId": "ddd883d0-dc98-4790-d3cf-b6d2073b6020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'f1': 0.7799385559623664,\n",
       " 'precision': 0.7827644591301087,\n",
       " 'recall': 0.7795275590551181}"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "Zu5k8lCgtOks",
    "outputId": "bb8b5993-6d69-4f1e-9c80-9e05580fe7a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>0.782152</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.782152</td>\n",
       "      <td>0.779088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.778385</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.778288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.785557</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.781439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.775989</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.772231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.770603</td>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.766934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.817793</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.816933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>0.765092</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>0.765092</td>\n",
       "      <td>0.759687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_results</th>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.779939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy  precision    recall        f1\n",
       "baseline                 0.792651   0.811139  0.792651  0.786219\n",
       "simple_dense             0.782152   0.786845  0.782152  0.779088\n",
       "lstm                     0.778215   0.778385  0.778215  0.778288\n",
       "gru                      0.783465   0.785557  0.783465  0.781439\n",
       "bidirectional            0.774278   0.775989  0.774278  0.772231\n",
       "conv1d                   0.769029   0.770603  0.769029  0.766934\n",
       "tf_hub_sentence_encoder  0.817585   0.817793  0.817585  0.816933\n",
       "tf_hub_10_percent_data   0.765092   0.774665  0.765092  0.759687\n",
       "ensemble_results         0.779528   0.782764  0.779528  0.779939"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Birleştirilmiş modelimizin sonuçlarını DataFrame sonuçlarına ekleyin\n",
    "all_model_results.loc[\"ensemble_results\"] = ensemble_results\n",
    "# Doğruluğu, sonuçların geri kalanıyla aynı ölçeğe dönüştürün\n",
    "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100\n",
    "\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4reoQhREtdCX"
   },
   "source": [
    "Yığılmış model diğer modellere karşı nasıl bir sonuç verdi?\n",
    "\n",
    "> 🔑 **Not:** Modelimizin sonuçlarının çoğu benzer görünüyor. Bu, verilerimizden öğrenilebileceklerin bazı sınırlamaları olduğu anlamına gelebilir. Modelleme denemelerinizin çoğu benzer sonuçlar verdiğinde, verilerinizi tekrar gözden geçirmek iyi bir fikirdir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUrQU7ZitpTP"
   },
   "source": [
    "## Eğitilmiş Bir Modeli Kaydetme ve Yükleme\n",
    "\n",
    "Eğitim süresi çok uzun sürmese de, yeniden eğitmek zorunda kalmamak için eğitilmiş modellerinizi kaydetmek iyi bir uygulamadır.\n",
    "\n",
    "Modellerinizi kaydetmek, aynı zamanda, bir web uygulamasında olduğu gibi, dizüstü bilgisayarınızın dışında başka bir yerde kullanmak üzere dışa aktarmanıza da olanak tanır.\n",
    "\n",
    "[TensorFlow'da bir modeli kaydetmenin] iki ana yolu vardır(https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):\n",
    "1. `HDF5` biçimi.\n",
    "2. `KayıtlıModel` biçimi (varsayılan).\n",
    "\n",
    "İkisine de bir göz atalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "V06p1K_DtW0R"
   },
   "outputs": [],
   "source": [
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJvMM0qat4-F"
   },
   "source": [
    "Bir modeli `HDF5` olarak kaydederseniz, tekrar yüklerken TensorFlow'a kullandığınız özel nesneler hakkında bilgi vermeniz gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "dUQU0y5Ht2H1"
   },
   "outputs": [],
   "source": [
    "# Modeli özel Hub Katmanı ile yükleyin (HDF5 formatı için gereklidir)\n",
    "loaded_model_6 = tf.keras.models.load_model(\n",
    "    \"model_6.h5\", \n",
    "    custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25v2aL98uI8_",
    "outputId": "a377b141-1d27-47b9-8d45-698b4f22f28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 9ms/step - loss: 0.4258 - accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4257993996143341, 0.817585289478302]"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yüklenen modelimiz nasıl performans gösteriyor?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcqJG8uluReQ"
   },
   "source": [
    "Hedef modelimizde `save()` yöntemini çağırmak ve ona bir dosya yolu iletmek, modelimizi `SavedModel` formatında kaydetmemizi sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfU9R2EDuNvw",
    "outputId": "014c0edf-c159-4506-dde3-95d2f0ec0c24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
     ]
    }
   ],
   "source": [
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mev4N2N0ueV_"
   },
   "source": [
    "SavedModel biçimini (varsayılan) kullanırsanız, `tensorflow.keras.models.load_model()` işlevini kullanarak özel nesneler belirtmeden modelinizi yeniden yükleyebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "7pDgUTDIuV3Z"
   },
   "outputs": [],
   "source": [
    "# TF Hub Cümle Kodlayıcıyı Yükle SavedModel\n",
    "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t2pginmuoWo",
    "outputId": "b0de9360-51ee-489a-f81c-f643ce2e9c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 10ms/step - loss: 0.4258 - accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4257993996143341, 0.817585289478302]"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yüklenen SavedModel biçimini değerlendirin\n",
    "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izamFwh3uxj0"
   },
   "source": [
    "Gördüğünüz gibi, modelimizi her iki formatta da kaydedip yüklemek aynı performansı veriyor.\n",
    "\n",
    "> 🤔 **Soru:** \"KayıtlıModel\" biçimini mi yoksa \"HDF5\" biçimini mi kullanmalısınız?\n",
    "\n",
    "Çoğu kullanım durumu için `SavedModel` formatı yeterli olacaktır. Ancak bu, TensorFlow'a özel bir standarttır. Daha genel amaçlı bir veri standardına ihtiyacınız varsa, \"HDF5\" daha iyi olabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ayb2-i7u1eVh"
   },
   "source": [
    "## En Yanlış Örnekleri Bulma\n",
    "\n",
    "Daha önce bahsetmiştik ki, modelleme deneylerimizin çoğu, farklı türde modeller kullanmamıza rağmen benzer sonuçlar veriyorsa, verilere geri dönüp bunun neden olabileceğini incelemenin iyi bir fikir olduğundan bahsetmiştik.\n",
    "\n",
    "Verilerinizi incelemenin en iyi yollarından biri, modelinizin tahminlerini sıralamak ve onun en yanlış yaptığı örnekleri bulmaktır, yani hangi tahminlerin yüksek tahmin olasılığı vardı ama yanlış çıktı.\n",
    "\n",
    "Bir kez daha, görselleştirme sizin arkadaşınızdır. Görselleştirin, görselleştirin, görselleştirin.\n",
    "\n",
    "İşleri görsel hale getirmek için, en iyi performans gösteren modelimizin tahmin olasılıklarını ve sınıflarını doğrulama örnekleriyle (metin ve kesin doğruluk etiketleri) birlikte alalım ve bunları bir panda DataFrame'de birleştirelim.\n",
    "\n",
    "* En iyi modelimiz hala mükemmel değilse, hangi örnekler yanlış gidiyor?\n",
    "* Hangileri en yanlış?\n",
    "* Yanlış olan bazı etiketler var mı? Örneğin. model doğru anlıyor ancak temel doğruluk etiketi bunu yansıtmıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "teTBGHc-1dJT",
    "outputId": "eb2dd238-86b8-46ce-d4d1-8df9f04d3cf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.824494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.211150\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.824494\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.986701\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.232937\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.771707"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                       \"target\": val_labels,\n",
    "                       \"pred\": model_6_preds,\n",
    "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5MEyT4y1wbe"
   },
   "source": [
    "Şimdi modelimizin yanlış tahminlerini bulalım (burada `target != pred`) ve bunları tahmin olasılıklarına göre sıralayalım (`pred_prob` sütunu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "lsVI8iy4xl1y",
    "outputId": "23515707-fcfe-40f5-f4a8-864b1fb40ae1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.834798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>The Sound of Arson</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.824494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  pred_prob\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.933326\n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   0.906695\n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   0.883666\n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.878714\n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.874096\n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.868922\n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.834798\n",
       "144                                 The Sound of Arson       0   1.0   0.831975\n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.826876\n",
       "1    FedEx no longer to transport bioterror germs i...       0   1.0   0.824494"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nG4tOgX15UF"
   },
   "source": [
    "Son olarak, örnek metni, doğruluk etiketini, tahmin sınıfını ve tahmin olasılığını görselleştirmek için bazı kodlar yazabiliriz. Örneklerimizi tahmin olasılığına göre sıraladığımız için, `en yanlış` DataFrame'imizin başındaki örneklere bakmak bize yanlış pozitifler gösterecektir.\n",
    "\n",
    "Bir hatırlatıcı:\n",
    "* `0` = Gerçek bir felaket Tweet değil\n",
    "* `1` = Gerçek felaket Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmA_8uIy11V-",
    "outputId": "c20495bd-08fc-47eb-d73c-172ecd7957ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1, Prob: 0.9333264827728271\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.9066951870918274\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8836658596992493\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.878714382648468\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8740962147712708\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8689219355583191\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8347980976104736\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8319746851921082\n",
      "Text:\n",
      "The Sound of Arson\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8268764019012451\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8244935274124146\n",
      "Text:\n",
      "FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in most_wrong[:10].itertuples(): \n",
    "  _, text, target, pred, prob = row\n",
    "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swmum05z2B1S",
    "outputId": "64ecc599-6cb4-4d44-eb09-be78aaf91003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0, Prob: 0.07638642191886902\n",
      "Text:\n",
      "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06680670380592346\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06613775342702866\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06331083923578262\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.060991670936346054\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.04729391261935234\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.043367695063352585\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.04216489568352699\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.0363759845495224\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.030536090955138206\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# En yanlış yanlış negatifleri kontrol edin (model 1 tahmin etmeliyken 0 tahmin etti)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "  _, text, target, pred, prob = row\n",
    "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeapW-xB2mRi"
   },
   "source": [
    "En yanlış örneklerle ilgili ilginç bir şey fark ettiniz mi? Etiketler doğru mu? Geri dönüp olmayan etiketleri düzeltirsek ne olur sizce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su5w1vU52sDg"
   },
   "source": [
    "## Test Veri Seti Üzerinde Tahminler Yapmak\n",
    "\n",
    "Pekala, modelimizin doğrulama setinde nasıl performans gösterdiğini gördük. Peki ya test veri seti?\n",
    "\n",
    "Test veri seti için etiketlerimiz yok, bu yüzden bazı tahminler yapmamız ve bunları kendimiz incelememiz gerekecek. Test veri setinden rastgele örnekler üzerinde tahminler yapmak için bazı kodlar yazalım ve görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkHu_REw2L0F",
    "outputId": "2f570c0f-4ee6-4a90-c989-fe1db24c3753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1, Prob: 0.5674287676811218\n",
      "Text:\n",
      "Marin Sr37 / Sr121 **Trfc Collision-Unkn Inj** http://t.co/yqJVEVhSzx\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.18044838309288025\n",
      "Text:\n",
      "Sometimes blood ain't no thicker than water and sometimes family will bring you down quicker than strangers ???????\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 1, Prob: 0.9360947608947754\n",
      "Text:\n",
      "Agricultural Buildings on Fire - Aldwark - NYorks Fire &amp; Rescue Service \n",
      "\n",
      "Still grim news but fewer piglets caught up http://t.co/0kjCWG6pN9\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 1, Prob: 0.936579704284668\n",
      "Text:\n",
      "See how a judge ruled in this 2009 accident at #JFK Airport? involving Korean Air?.\n",
      "\n",
      "http://t.co/Yh1cGlN3rl http://t.co/6F5ShPKjOB\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.09350459277629852\n",
      "Text:\n",
      "@FollowerOfDole 'Give me your lunch money ner-' *flattened by falling quarter*\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.04109868034720421\n",
      "Text:\n",
      "100  1' MIX NEW FLAT DOUBLE SIDED LINERLESS BOTTLE CAPS YOU CHOOSE MIX FLATTENED - Full reÛ_ http://t.co/61fALvOCuK http://t.co/1MuTpFcgDL\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 1, Prob: 0.6397950649261475\n",
      "Text:\n",
      "@Trubeque Destruction magic's fine just don't go burning any buildings.\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.125456303358078\n",
      "Text:\n",
      "Time heals all wounds. And if it doesn't you name them something other than wounds and agree to let them stay. ????\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.1686350554227829\n",
      "Text:\n",
      "Nooooo the village hotty is dead ???????? #Emmerdale\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.0520525760948658\n",
      "Text:\n",
      "Businesses cre deluged with invoices. Make yours stand out with colour or shape and it's likely to rise to the top of the pay' cile.\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "  pred_prob = tf.squeeze(model_6.predict([test_sample]))\n",
    "  pred = tf.round(pred_prob)\n",
    "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{test_sample}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJlEp3ZD3S_w"
   },
   "source": [
    "Modelinizin görünmeyen veriler üzerinde nasıl performans gösterdiğine ve ardından gerçek testte nasıl performans gösterebileceğine bir göz atmak için bu tür görselleştirme kontrollerini mümkün olduğunca sık yapmak önemlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc17Kg1V3yn_"
   },
   "source": [
    "## Hız/Puan Dengesi\n",
    "\n",
    "Yapacağımız son testlerden biri, en iyi modelimiz ve temel modelimiz arasındaki hız/puan dengelerini bulmaktır.\n",
    "\n",
    "Bu neden önemli?\n",
    "\n",
    "Deneme yoluyla bulduğunuz en iyi performans gösteren modeli seçmek cazip gelse de, bu model aslında bir üretim ortamında çalışmayabilir.\n",
    "\n",
    "Bu şekilde ifade edin, Twitter olduğunuzu ve saatte 1 milyon Tweet aldığınızı hayal edin (bu uydurma bir sayıdır, gerçek sayı çok daha yüksektir). Ve Tweet'leri okumak ve bir felaketle ilgili ayrıntıları gerçek zamanlıya yakın bir şekilde yetkilileri uyarmak için bir felaket algılama sistemi oluşturmaya çalışıyorsunuz.\n",
    "\n",
    "İşlem gücü ücretsiz değildir, bu nedenle proje için tek bir işlem makinesiyle sınırlısınız. Bu makinede, modellerinizden biri %80 doğrulukla saniyede 10.000 tahminde bulunurken, modellerinizden biri (daha büyük bir model) %85 doğrulukla saniyede 100 tahmin yapar.\n",
    "\n",
    "Hangi modeli seçersiniz?\n",
    "\n",
    "İkinci modelin performans artışı, ekstra kapasiteyi kaçırmaya değer mi? Tabii ki burada deneyebileceğiniz birçok seçenek var, ilk modele mümkün olduğunca çok Tweet göndermek ve ardından modelin en az emin olduğu şeyleri ikinci modele göndermek gibi.\n",
    "\n",
    "Buradaki amaç, deney yoluyla bulduğunuz en iyi modeli göstermektir, üretimde kullandığınız model olmayabilir.\n",
    "\n",
    "Bunu daha somut hale getirmek için, bir model ve bir dizi örnek alacak bir fonksiyon yazalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "KfmeyxIN25Js"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def pred_timer(model, samples):\n",
    "  start_time = time.perf_counter() \n",
    "  model.predict(samples) \n",
    "  end_time = time.perf_counter() \n",
    "  total_time = end_time-start_time \n",
    "  time_per_pred = total_time/len(val_sentences)\n",
    "  return total_time, time_per_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIhvYpiI4CkB"
   },
   "source": [
    "İyi görünüyor!\n",
    "\n",
    "Şimdi en iyi performans gösteren modelimizin (`model_6`) ve temel modelimizin (`model_0`) tahmin sürelerini değerlendirmek için `pred_timer()` fonksiyonumuzu kullanalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Opldd5u4AXF",
    "outputId": "eb99d7fc-36a6-4a2b-8ede-d75141b7ba4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22613020000062534, 0.00029675879265173927)"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
    "model_6_total_pred_time, model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ysJQtUM4HTR",
    "outputId": "70dcff91-d2a2-4ddd-9aee-35e079541754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.016506090001712437, 2.1661535435318158e-05)"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
    "baseline_total_pred_time, baseline_time_per_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAwscxo24QBn"
   },
   "source": [
    "Mevcut donanımımızla (benim durumumda bir Google Colab not defteri kullanıyorum) en iyi performans gösteren modelimiz, temel modelimiz olarak tahminler yapmak için 10 kat daha fazla zaman alıyor. Bu ekstra tahmin süresi buna değer mi?\n",
    "\n",
    "Modelimizin F1 puanlarıyla tahmin başına süreyi karşılaştıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "ahUavIu64Ivm",
    "outputId": "5d6d00e9-75e4-4194-d8df-02bf7fb02c66"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAG5CAYAAADYudMnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xVdZ3/8ddHLmKWd5pJQcFSFOHI5Yi3StQMS0et1PCn/fLSmJnZNBOTzuRklr+fZb+cdDSlRmm0RFMzUgsmxdS8HgZFUVFUEtAMCTQIlMvn98de57g5nhvCPuesw+v5eOwHa3/Xd33Xd333Ft5+11p7RWYiSZKkctisqzsgSZKkjjO8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJGN4kaT1ExL9ExI+7uh/dXUSMjYgFVe9nR8TYd9DOhyJizkbtnFRyhjepG4qIeRGxIiKWVb12LNZNjIg5EbE2Ik7u4q72aM0DCEBm/p/M/FxX9amsMnOvzLy7vXoRkRHxgart7s3MITXtnFQyhjep+/q7zHx31eulovwx4Ezgf7qwbwBERO9Ncd9lszHGKiJ6bYy+SNpwhjepZDLz8sy8E1jZXt2I6BcR10XE4ohYGhGPRMTfFOu2i4hrIuKliFgSEbdWbff3ETE3Iv4cEVMaZ/2KdRkRX4yIZ4Fni7IjI+LRYh/3R0RdK/35YUR8r1nZLyPiH4vlHSPi5ohYFBEvRMTZVfXOj4ibiuN5HTg5IsZERENEvB4Rr0TE94u6b5sxK2YzP1Ist7hds/pbAr8Gdqye/Sz6cV1RZ1AxHqdExPxiHM+IiH0iYlYxHv/RrN1TI+Kpou7UiNillbFqbPv04jN6OSK+WrV+s4g4JyKeKz7fGyNiu2bbnhYRLwJ3tdD+2IhYUJwGfrUYnxOr1k8qPq87ImI5cHA7n88WxTZLIuJJYJ82xr9Xsd/nIuIvETEjIgZGxD1F9ceK8f50888yIvaMiLuLsZ0dEUc16/PlEXF70e5DEfH+lsZXKrXM9OXLVzd7AfOAj7RT5z7g5HbqfB74FfAuoBcwGtiqWHc7cAOwLdAHOKgoPwR4FRgFbA5cBtxT1WYC/w1sB2wBjAT+BOxb7OOzRf83b6E/HwbmA1G83xZYAexI5X8mZwD/BvQFdgWeB8YVdc8HVgHHFHW3AB4APlOsfzewX7E8FljQ2pi2tl0L/W2pnfOB64rlQcV4XAn0Az5KJVTfCrwX2KkYm8axPRqYC+wJ9Aa+Dtzfyr4b274e2BIYDiyqOoYvAw8CA4rP6Srg+mbb/lex7RatHNtq4PvF9gcBy4EhxfpJwGvAgcV4v6udz+ci4N7iezEQeKJ67JqN/wTgcWAIEMDewPZV368PtPQZUPmezgX+pejDIcBfmvV5MTCmGN+fApO7+r9nX7429suZN6n7urWYXVhaPSu2nlYB21P5x3BNZs7IzNcj4n3Ax4AzMnNJZq7KzN8V25wIXJ2Z/5OZbwDnAvtHxKCqdv9vZv45M1cApwNXZeZDxT5+ArwB7NdCf+6l8o/zh4r3xwIPZOWU8D5A/8y8IDPfzMzngR8B46u2fyAzb83MtcW+VwEfiIgdMnNZZj64HuPyTrZrzbcyc2VmTqMSgK7PzD9l5sLimEcW9c6gMnZPZeZq4P8AI1qbfSt8MzOXZ+bjwDXACVVt/WtmLig+p/OBY2PdU6TnF9uuaKP98zLzjeLzvx04vmrdLzPz95m5lkp4bOvzOR64sPhezAcubWOfnwO+nplzsuKxzFzcRv1G+1EJ2xcVfbgLuK1qTAB+kZkPF+P7U2BEB9qVSsXwJnVfx2TmNsXrmI5sEOve4LAzcC0wFZhcnHr7bkT0oTIz8ufMXNJCMzsCf2h8k5nLqMxm7FRVZ37V8i7AP1UFzaVF+zvSTGYmMJm3/rH9X1T+gW1sZ8dm7fwL8Det7BfgNGB34OmonBI+srWx2UjbteaVquUVLbx/d7G8C/CDquP7M5WZp+qxba76mP/AW+O6C/CLqraeAtbQ9ng1tyQzl7fSfvPt2/t8dmyhr60ZCDzXTt9asiMwvwiT1fupHr8/Vi3/lbfGXuoxvOBX6kEys6V/qL4JfLOYObsDmFP8uV1EbJOZS5vVf4nKP9RA07Vf2wMLq3dVtTyfyozLhR3s5vXAtIi4iMqp1k9UtfNCZu7Wxra5zpvMZ4ETImIz4JPATRGxPZXZr3dVHUMvoH972zULMm/b30bQOFY/bbfmWwYCTxfLO1P5fBrbOjUzf998g6pZ0vb6v21EbFl13DtTOd3ZqPnn3Nbn83LR19lVbbVmPvD+ZvvqiJeAgRGxWVWA2xl4Zj3bkUrNmTepZCKib0T0ozJj0ycqNyW0+N9yRBwcEcOL8PI6ldOFazPzZSoX418REdtGRJ+I+HCx2fXAKRExIiI2p3Jq76HMnNdKl34EnBER+0bFlhFxRES8p6XKmTmTyjV1PwamVoXHh4G/RMTXiovfe0XEsIjYp6V2iuM7KSL6F/+QN7azlso/5v2KfvShcm3Z5h3YrrlXgO0jYuvW+rCergTOjYi9in5sHRHHtbPNeRHxrmKbU6hcp9jY1oWNp1wjon9EHP0O+vTN4jv1IeBI4Oet1Gvv87mxOLZtI2IA8KU29vlj4FsRsVvxnakrQjdUxnzXVrZ7iMps2j8X39mxwN9Rmc2VNhmGN6l8plE5FXcAMLFY/nArdf8WuIlKcHsK+B2VU6kAn6ES5p6mclH9PwBk5m+B84CbqcymvJ91rztbR2Y2AH8P/AewhMoF5Se3cww/Az5S/NnYzhoq4WEE8AJvBby2gtPhwOyIWAb8ABifmSsy8zUqP6fyYyozhsuBBe1t18KxPU0lzD5fnCp826ng9ZGZvwC+Q+U09utUZp4+1s5mv6MypncC3yuuq6Po9xQqs5h/oXLzwr7r2aU/UvnMXqJy+vqM4phb6nt7n883qZzCfIHKd/TaFppp9H0qYW8ale/mf1K5AQUq1+79pBjv6uvvyMw3qYS1jxX7vwL43631WeqpGu/4kiR1I8WpzxeAPsXF9xu7/bFU7podsLHbllRbzrxJkiSViOFNkiSpRDxtKkmSVCLOvEmSJJXIJvE7bzvssEMOGjSoq7shSZLUrhkzZryamf1bW79JhLdBgwbR0NDQ1d2QJElqV0S09YQST5tKkiSVieFNkiSpRAxvkiRJJbJJXPPWklWrVrFgwQJWrlzZ1V3RJq5fv34MGDCAPn36dHVXJEklsMmGtwULFvCe97yHQYMGERFd3R1tojKTxYsXs2DBAgYPHtzV3ZEklcAme9p05cqVbL/99gY3damIYPvtt3cGWJLUYZtseAMMbuoW/B5KktbHJh3eJEmSysbw1oXmzZvHsGHDatL23XffzZFHHgnAlClTuOiii2qyH0mS1Lk22RsWNiVHHXUURx11VFd3Q5IkbQTOvHXQrTMXcuBFdzH4nNs58KK7uHXmwo3S7urVqznxxBPZc889OfbYY/nrX//KBRdcwD777MOwYcM4/fTTyUwALr30UoYOHUpdXR3jx48HYPny5Zx66qmMGTOGkSNH8stf/vJt+5g0aRJnnXUWACeffDJnn302BxxwALvuuis33XRTU72LL76YffbZh7q6Or7xjW9slOOTJEkbl+GtA26duZBzb3mchUtXkMDCpSs495bHN0qAmzNnDmeeeSZPPfUUW221FVdccQVnnXUWjzzyCE888QQrVqzgtttuA+Ciiy5i5syZzJo1iyuvvBKACy+8kEMOOYSHH36Y6dOnM2HCBJYvX97mPl9++WXuu+8+brvtNs455xwApk2bxrPPPsvDDz/Mo48+yowZM7jnnns2+PgkSdLGZXjrgIunzmHFqjXrlK1YtYaLp87Z4LYHDhzIgQceCMBJJ53Efffdx/Tp09l3330ZPnw4d911F7Nnzwagrq6OE088keuuu47evStnvKdNm8ZFF13EiBEjGDt2LCtXruTFF19sc5/HHHMMm222GUOHDuWVV15pamfatGmMHDmSUaNG8fTTT/Pss89u8PFJkqSNy2veOuClpSvWq3x9NP+ZiIjgzDPPpKGhgYEDB3L++ec3/QbY7bffzj333MOvfvUrLrzwQh5//HEyk5tvvpkhQ4as005jKGvJ5ptv3rTceEo2Mzn33HP5/Oc/v8HHJElSjzLrRrjzAnhtAWw9AA79N6g7vsu648xbB+y4zRbrVb4+XnzxRR544AEAfvazn/HBD34QgB122IFly5Y1XZO2du1a5s+fz8EHH8x3vvMdXnvtNZYtW8a4ceO47LLLmkLYzJkz31E/xo0bx9VXX82yZcsAWLhwIX/605829PAkSSq3WTfCr86G1+YDWfnzV2dXyruIM28dMGHcEM695fF1Tp1u0acXE8YNaWOrjhkyZAiXX345p556KkOHDuULX/gCS5YsYdiwYfzt3/4t++yzDwBr1qzhpJNO4rXXXiMzOfvss9lmm20477zz+Id/+Afq6upYu3YtgwcPbrpGbn189KMf5amnnmL//fcH4N3vfjfXXXcd733vezf4GCVJKq07L4BVzc60rVpRKe+i2bdonLHpyerr67OhoWGdsqeeeoo999yzw23cOnMhF0+dw0tLV7DjNlswYdwQjhm508buqjZR6/t9lCR1kvO3AVrKSgHnL63JLiNiRmbWt7bembcOOmbkToY1SZI2NVsPKE6ZtlDeRbzmTZIkqTWH/hv0aXaNe58tKuVdxPAmSZLUmrrj4e8uha0HAlH58+8u7dK7TT1tKkmS1Ja647s0rDXnzJskSVKJGN4kSZJKxPAmSZJUIoa3LrJ06VKuuOKKpvcTJkxgr732YsKECS3WP/nkk5uettBRgwYN4tVXX92gfq6vf//3f+evf/1rp+6zK919990ceeSRXd0NSdImxPDWUbNuhEuGVX6s75JhG/xYjObhbeLEicyaNYuLL754Q3vapTa18La+Vq9e3dVdkCSVnOGtI2rwXLNzzjmH5557jhEjRnDYYYexbNkyRo8ezQ033NDqNvfccw8HHHAAu+66a9MsXPOZn7POOotJkyY1vf/ud7/L8OHDGTNmDHPnzm217Z///OcMGzaMvffemw9/+MNA5ZFcEyZMYJ999qGuro6rrrqqaZ9jx47l2GOPZY899uDEE08kM7n00kt56aWXOPjggzn44IMBmDZtGvvvvz+jRo3iuOOOa3p26qBBg/jGN77BqFGjGD58OE8//TQAy5Yt45RTTmH48OHU1dVx8803t9lOS2bMmMFBBx3E6NGjGTduHC+//DIAY8eO5Wtf+xpjxoxh991359577206zq9+9asMGzaMuro6LrvsMgDuvPNORo4cyfDhwzn11FN54403APjNb37DHnvswahRo7jlllua9rt8+XJOPfVUxowZw8iRI/nlL38JwKRJkzjqqKM45JBDOPTQQ1vttyRJHZKZPf41evTobO7JJ598W1mrvr9X5je2evvr+3t1vI1mXnjhhdxrr7e233LLLdus/9nPfjaPPfbYXLNmTc6ePTvf//73Z2bm9OnT84gjjmiq98UvfjGvueaazMzcZZdd8tvf/nZmZv7kJz9Zp15zw4YNywULFmRm5pIlSzIz86qrrspvfetbmZm5cuXKHD16dD7//PM5ffr03GqrrXL+/Pm5Zs2a3G+//fLee+9t2ueiRYsyM3PRokX5oQ99KJctW5aZmRdddFF+85vfbKp36aWXZmbm5ZdfnqeddlpmZv7zP/9zfvnLX27q15///Oc222nuzTffzP333z//9Kc/ZWbm5MmT85RTTsnMzIMOOij/8R//MTMzb7/99jz00EMzM/OKK67IT33qU7lq1arMzFy8eHGuWLEiBwwYkHPmzMnMzM985jN5ySWXNJU/88wzuXbt2jzuuOOaxvXcc8/Na6+9tmkMd9ttt1y2bFlec801udNOO+XixYtbHf/1+j5Kkno0oCHbyDX+zltHvLZg/cpr5JhjjmGzzTZj6NChvPLKKx3a5oQTTmj68ytf+Uqr9Q488EBOPvlkjj/+eD75yU8CldmuWbNmNc3yvfbaazz77LP07duXMWPGMGBA5dEgI0aMYN68eXzwgx9cp80HH3yQJ598kgMPPBCAN998s+nB90DTfkaPHt00g/Xb3/6WyZMnN9XZdtttue2229psp9qcOXN44oknOOyww4DKrNr73ve+Fvc5b968pn2eccYZ9O5d+c9hu+2247HHHmPw4MHsvvvuAHz2s5/l8ssvZ+zYsQwePJjddtsNgJNOOomJEyc2jdeUKVP43ve+B8DKlSt58cUXATjssMPYbrvtWh1/SZI6yvDWEd3kuWabb75503IlmEPv3r1Zu3ZtU/nKlSvX2SYiWlxu7sorr+Shhx7i9ttvZ/To0cyYMYPM5LLLLmPcuHHr1L377rvX6UuvXr1avJYrMznssMO4/vrr2zye1rbvaDvN6+6111488MADG7TPdyIzufnmmxkyZMg65Q899BBbbrnlRt2XJGnT5TVvHVGD55q95z3v4S9/+csGdgx22WUXnnzySd544w2WLl3KnXfeuc76xmvobrjhhlZnqwCee+459t13Xy644AL69+/P/PnzGTduHD/84Q9ZtWoVAM888wzLly9vsz/Vx7Xffvvx+9//vulau+XLl/PMM8+0uf1hhx3G5Zdf3vR+yZIl69XOkCFDWLRoUVN4W7VqFbNnz253n1dddVVTmPvzn//MkCFDmDdvXtM+r732Wg466CD22GMP5s2bx3PPPQewTqAcN24cl112WVOwnjlzZpv7lSTpnTC8dUQNnmu2/fbbc+CBBzJs2LBWfx6kIwYOHMjxxx/PsGHDOP744xk5cuQ665csWUJdXR0/+MEPuOSSS1ptZ8KECQwfPpxhw4ZxwAEHsPfee/O5z32OoUOHMmrUKIYNG8bnP//5dmerTj/9dA4//HAOPvhg+vfvz6RJkzjhhBOoq6tj//33b7oxoTVf//rXWbJkSdPNE9OnT1+vdvr27ctNN93E1772Nfbee29GjBjB/fff3+Y+P/e5z7HzzjtTV1fH3nvvzc9+9jP69evHNddcw3HHHcfw4cPZbLPNOOOMM+jXrx8TJ07kiCOOYNSoUbz3ve9taue8885j1apV1NXVsddee3Heeee1uV9Jkt6JaJwl6Mnq6+uzoaFhnbKnnnqKPffcs4t6JK3L76MkqVFEzMjM+tbWO/MmSZJUIjUNbxFxeETMiYi5EXFOC+t3jojpETEzImZFxMeL8u2L8mUR8R/Ntrm7aPPR4vXe5u2W2YUXXsiIESPWeV144YWlab8zfeITn3jbsUydOrWruyVJUk3V7LRpRPQCngEOAxYAjwAnZOaTVXUmAjMz84cRMRS4IzMHRcSWwEhgGDAsM8+q2uZu4KuZue550Da0dtp0jz32aPMOTKkzZCZPP/20p00lSUDXnjYdA8zNzOcz801gMnB0szoJbFUsbw28BJCZyzPzPmAlNdKvXz8WL17MpnDNn7qvzGTx4sX069evq7siSSqJWv7O205A9Y+jLQD2bVbnfGBaRHwJ2BL4SAfbviYi1gA3A9/OFhJYRJwOnA6w8847v62BAQMGsGDBAhYtWtTBXUq10a9fv6YfPJYkqT1d/SO9JwCTMvP/RcT+wLURMSwz17axzYmZuTAi3kMlvH0G+K/mlTJzIjARKqdNm6/v06cPgwcP3igHIUmS1Flqedp0ITCw6v2AoqzaacCNAJn5ANAP2KGtRjNzYfHnX4CfUTk9K0mStEmoZXh7BNgtIgZHRF9gPDClWZ0XgUMBImJPKuGt1fOYEdE7InYolvsARwJP1KDvkiRJ3VLNTptm5uqIOAuYCvQCrs7M2RFxAdCQmVOAfwJ+FBFfoXLzwsmN169FxDwqNzP0jYhjgI8CfwCmFsGtF/Bb4Ee1OgZJkqTuZpN9woIkSVJ35BMWJEmSehDDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJVLT8BYRh0fEnIiYGxHntLB+54iYHhEzI2JWRHy8KN++KF8WEf/RbJvREfF40ealERG1PAZJkqTupGbhLSJ6AZcDHwOGAidExNBm1b4O3JiZI4HxwBVF+UrgPOCrLTT9Q+Dvgd2K1+Ebv/eSJEndUy1n3sYAczPz+cx8E5gMHN2sTgJbFctbAy8BZObyzLyPSohrEhHvA7bKzAczM4H/Ao6p4TFIkiR1K7UMbzsB86veLyjKqp0PnBQRC4A7gC91oM0F7bQJQEScHhENEdGwaNGi9em3JElSt9XVNyycAEzKzAHAx4FrI2Kj9CkzJ2ZmfWbW9+/ff2M0KUmS1OVqGd4WAgOr3g8oyqqdBtwIkJkPAP2AHdppc0A7bUqSJPVYtQxvjwC7RcTgiOhL5YaEKc3qvAgcChARe1IJb62e48zMl4HXI2K/4i7T/w38shadlyRJ6o5616rhzFwdEWcBU4FewNWZOTsiLgAaMnMK8E/AjyLiK1RuXji5uBGBiJhH5WaGvhFxDPDRzHwSOBOYBGwB/Lp4SZIkbRKiyEo9Wn19fTY0NHR1NyRJktoVETMys7619V19w4IkSZLWg+FNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQiNQ1vEXF4RMyJiLkRcU4L63eOiOkRMTMiZkXEx6vWnVtsNycixlWVz4uIxyPi0YhoqGX/JUmSupvetWo4InoBlwOHAQuARyJiSmY+WVXt68CNmfnDiBgK3AEMKpbHA3sBOwK/jYjdM3NNsd3BmflqrfouSZLUXdVy5m0MMDczn8/MN4HJwNHN6iSwVbG8NfBSsXw0MDkz38jMF4C5RXuSJEmbtFqGt52A+VXvFxRl1c4HToqIBVRm3b7UgW0TmBYRMyLi9NZ2HhGnR0RDRDQsWrTonR+FJElSN9LVNyycAEzKzAHAx4FrI6K9Pn0wM0cBHwO+GBEfbqlSZk7MzPrMrO/fv//G7bUkSVIXqWV4WwgMrHo/oCirdhpwI0BmPgD0A3Zoa9vMbPzzT8Av8HSqJEnahNQyvD0C7BYRgyOiL5UbEKY0q/MicChAROxJJbwtKuqNj4jNI2IwsBvwcERsGRHvKepvCXwUeKKGxyBJktSt1Oxu08xcHRFnAVOBXsDVmTk7Ii4AGjJzCvBPwI8i4itUrmU7OTMTmB0RNwJPAquBL2bmmoj4G+AXEdHY959l5m9qdQySJEndTVSyUs9WX1+fDQ3+JJwkSer+ImJGZta3tr6rb1iQJEnSejC8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJGN4kSZJKxPAmSZJUIoY3SZKkEjG8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJdCi8RcTuEXFnRDxRvK+LiK/XtmuSJElqrqMzbz8CzgVWAWTmLGB8rTolSZKklnU0vL0rMx9uVrZ6Y3dGkiRJbetoeHs1It4PJEBEHAu8XLNeSZIkqUW9O1jvi8BEYI+IWAi8AJxYs15JkiSpRe2Gt4joBZyZmR+JiC2BzTLzL7XvmiRJkpprN7xl5pqI+GCxvLz2XZIkSVJrOnradGZETAF+DjQFuMy8pSa9kiRJUos6Gt76AYuBQ6rKEjC8SZIkdaIOhbfMPKXWHZEkSVL7OvqEhQER8YuI+FPxujkiBtS6c5IkSVpXR3/n7RpgCrBj8fpVUSZJkqRO1NHw1j8zr8nM1cVrEtC/hv2SJElSCzoa3hZHxEkR0at4nUTlBgZJkiR1oo6Gt1OB44E/Unks1rGANzFIkiR1so7ebfoH4Kga90WSJEnt6Ojdpj+JiG2q3m8bEVfXrluSJElqSUdPm9Zl5tLGN5m5BBhZmy5JkiSpNR0Nb5tFxLaNbyJiOzr+dAZJkiRtJB0NYP8PeCAifg4ElRsWLqxZryRJktSijt6w8F8R0UDl2aYJfDIzn6xpzyRJkvQ2bZ42jYh3RUQfgCKs/TfQF9ijE/omSZKkZtq75u03wCCAiPgA8ACwK/DFiLiotl2TJElSc+2Ft20z89li+bPA9Zn5JeBjwBE17ZkkSZLepr3wllXLh1A5bUpmvgmsrVWnJEmS1LL2bliYFRHfAxYCHwCmAVT/YK8kSZI6T3szb38PvErlurePZuZfi/KhwPdq2C9JkiS1oM2Zt8xcAaxzY0JEjMrM+4H7a9kxSZIkvV1Hn7BQ7ccbvReSJEnqkHcS3mKj90KSJEkd8k7C2zc3ei8kSZLUIesd3jLzVoCI8CkLkiRJneydzLw1mrbReiFJkqQOafNu04i4tLVVQLu/9RYRhwM/AHoBP87M5neu7gz8pGirF3BOZt5RrDsXOA1YA5ydmVM70qYkSVJP1t6P9J4C/BPwRixHgIoAABMrSURBVAvrTmhrw4joBVwOHAYsAB6JiCnFA+4bfR24MTN/GBFDgTuAQcXyeGAvYEfgtxGxe7FNe21KkiT1WO2Ft0eAJ4rfdVtHRJzfzrZjgLmZ+XxRfzJwNFAdtBLYqljeGnipWD4amJyZbwAvRMTcoj060KYkSVKP1V54OxZY2dKKzBzczrY7AfOr3i8A9m1W53xgWkR8CdgS+EjVtg8223anYrm9NgGIiNOB0wF23nnndroqSZJUDu3dsPDuqkdi1cIJwKTMHAB8HLg2IjbkJoommTkxM+szs75///4bo0lJkqQu115QurVxISJuXs+2FwIDq94PKMqqnQbcCJCZDwD9gB3a2LYjbUqSJPVY7YW36qcp7LqebT8C7BYRgyOiL5UbEKY0q/MicChAROxJJbwtKuqNj4jNI2IwsBvwcAfblCRJ6rHau+YtW1luV2aujoizgKlUftbj6sycHREXAA2ZOYXKnaw/ioivFO2fnJkJzI6IG6nciLAa+GJmrgFoqc316ZckSVKZRSUrtbIyYg2wnMoM3BZA4/VvAWRmbtXatt1JfX19NjQ0dHU3JEmS2hURMzKzvrX1bc68ZWavjd8lSZIkvVMb5c5OSZIkdQ7DmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRAxvkiRJJWJ4kyRJKhHDmyRJUokY3iRJkkrE8CZJklQihjdJkqQSMbxJkiSViOFNkiSpRGoa3iLi8IiYExFzI+KcFtZfEhGPFq9nImJp1brvRMQTxevTVeWTIuKFqu1G1PIYJEmSupPetWo4InoBlwOHAQuARyJiSmY+2VgnM79SVf9LwMhi+QhgFDAC2By4OyJ+nZmvF9UnZOZNteq7JElSd1XLmbcxwNzMfD4z3wQmA0e3Uf8E4PpieShwT2auzszlwCzg8Br2VZIkqRRqGd52AuZXvV9QlL1NROwCDAbuKooeAw6PiHdFxA7AwcDAqk0ujIhZxWnXzVtp8/SIaIiIhkWLFm3osUiSJHUL3eWGhfHATZm5BiAzpwF3APdTmY17AFhT1D0X2APYB9gO+FpLDWbmxMysz8z6/v3717j7kiRJnaOW4W0h686WDSjKWjKet06ZApCZF2bmiMw8DAjgmaL85ax4A7iGyulZSZKkTUItw9sjwG4RMTgi+lIJaFOaV4qIPYBtqcyuNZb1iojti+U6oA6YVrx/X/FnAMcAT9TwGCRJkrqVmt1tmpmrI+IsYCrQC7g6M2dHxAVAQ2Y2BrnxwOTMzKrN+wD3VvIZrwMnZebqYt1PI6I/ldm4R4EzanUMkiRJ3U2sm5l6pvr6+mxoaOjqbkiSJLUrImZkZn1r67vLDQuSJEnqAMObJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJWI4U2SJKlEDG+SJEklYniTJEkqEcObJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJWI4U2SJKlEDG+SJEklYniTJEkqEcObJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJWI4U2SJKlEDG+SJEklYniTJEkqEcObJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJWI4U2SJKlEDG+SJEklYniTJEkqEcObJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJWI4U2SJKlEDG+SJEklYniTJEkqEcObJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJWI4U2SJKlEahreIuLwiJgTEXMj4pwW1l8SEY8Wr2ciYmnVuu9ExBPF69NV5YMj4qGizRsiom8tj0GSJKk7qVl4i4hewOXAx4ChwAkRMbS6TmZ+JTNHZOYI4DLglmLbI4BRwAhgX+CrEbFVsdl3gEsy8wPAEuC0Wh2DJElSd1PLmbcxwNzMfD4z3wQmA0e3Uf8E4PpieShwT2auzszlwCzg8IgI4BDgpqLeT4BjatJ7SZKkbqiW4W0nYH7V+wVF2dtExC7AYOCuougxKmHtXRGxA3AwMBDYHliamas70ObpEdEQEQ2LFi3a4IORJEnqDrrLDQvjgZsycw1AZk4D7gDupzIb9wCwZn0azMyJmVmfmfX9+/ff2P2VJEnqErUMbwupzJY1GlCUtWQ8b50yBSAzLyyuhzsMCOAZYDGwTUT07kCbkiRJPU4tw9sjwG7F3aF9qQS0Kc0rRcQewLZUZtcay3pFxPbFch1QB0zLzASmA8cWVT8L/LKGxyBJktSt9G6/yjuTmasj4ixgKtALuDozZ0fEBUBDZjYGufHA5CKYNeoD3Fu5P4HXgZOqrnP7GjA5Ir4NzAT+s1bHIEmS1N3EupmpZ6qvr8+Ghoau7oYkSVK7ImJGZta3tr673LAgSZKkDjC8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJGN4kSZJKxPAmSZJUIoY3SZKkEjG8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJGN4kSZJKxPAmSZJUIoY3SZKkEjG8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJGN4kSZJKxPAmSZJUIoY3SZKkEjG8SZIklYjhTZIkqUQMb5IkSSVieJMkSSoRw5skSVKJGN4kSZJKxPAmSZJUIoY3SZKkEjG8SZIklUjvru5A2d06cyEXT53DS0tXsOM2WzBh3BCOGblTV3dLkiT1UIa3DXDrzIWce8vjrFi1BoCFS1dw7i2PAxjgJElSTXjadANcPHVOU3BrtGLVGi6eOqeLeiRJkno6w9sGeGnpivUqlyRJ2lCGtw2w4zZbrFe5JEnShjK8bYAJ44awRZ9e65Rt0acXE8YN6aIeSZKkns4bFjZA400J3m0qSZI6i+FtAx0zcifDmiRJ6jSeNpUkSSoRw5skSVKJGN4kSZJKxPAmSZJUIoY3SZKkEqlpeIuIwyNiTkTMjYhzWlh/SUQ8WryeiYilVeu+GxGzI+KpiLg0IqIov7tos3G799byGCRJkrqTmv1USET0Ai4HDgMWAI9ExJTMfLKxTmZ+par+l4CRxfIBwIFAXbH6PuAg4O7i/YmZ2VCrvkuSJHVXtZx5GwPMzcznM/NNYDJwdBv1TwCuL5YT6Af0BTYH+gCv1LCvkiRJpVDL8LYTML/q/YKi7G0iYhdgMHAXQGY+AEwHXi5eUzPzqapNrilOmZ7XeDq1hTZPj4iGiGhYtGjRhh+NJElSN9BdblgYD9yUmWsAIuIDwJ7AACqB75CI+FBR98TMHA58qHh9pqUGM3NiZtZnZn3//v1rfgCSJEmdoZbhbSEwsOr9gKKsJeN565QpwCeABzNzWWYuA34N7A+QmQuLP/8C/IzK6VlJkqRNQi3D2yPAbhExOCL6UgloU5pXiog9gG2BB6qKXwQOiojeEdGHys0KTxXvdyi26wMcCTxRw2OQJEnqVmp2t2lmro6Is4CpQC/g6sycHREXAA2Z2RjkxgOTMzOrNr8JOAR4nMrNC7/JzF9FxJbA1CK49QJ+C/yovb7MmDHj1Yj4w0Y7uE3DDsCrXd2JTYxj3rkc787leHcux7tzbezx3qWtlbFuZpIqIqIhM+u7uh+bEse8cznencvx7lyOd+fq7PHuLjcsSJIkqQMMb5IkSSVieFNrJnZ1BzZBjnnncrw7l+PduRzvztWp4+01b5IkSSXizJskSVKJGN4kSZJKxPDWw0TE4RExJyLmRsQ5LazfPCJuKNY/FBGDqtadW5TPiYhx7bVZ/ADzQ0X5DcWPMRMRJ0fEouL5s49GxOdqe9Rdp5PH+6yiLBt/rLooj4i4tFg3KyJG1e6Iu1Y3Ge+xEfFa1ff732p3xF2rk8f7p0X5ExFxdfF7nn6/113fGeO9yXy/odPH/D8j4rHie3xTRLy7vX20KjN99ZAXlR8ufg7YFegLPAYMbVbnTODKYnk8cEOxPLSovzkwuGinV1ttAjcC44vlK4EvFMsnA//R1ePRA8d7JDAImAfsULWPj1N5hFwA+wEPdfXY9PDxHgvc1tXj0QPH++PFdzioPC7xC1Xlfr87b7w3ie93F435VlXtfh84p619tPVy5q1nGQPMzcznM/NNYDJwdLM6RwM/KZZvAg6NiCjKJ2fmG5n5AjC3aK/FNottDinaoGjzmBoeW3fUaeMNkJkzM3NeC/04GvivrHgQ2CYi3rdRj7R76C7jvano7PG+o/gOJ/AwledhN+7D73dFZ4z3pqSzx/x1qMwmA1tQeYJUW/toleGtZ9kJmF/1fkFR1mKdzFwNvAZs38a2rZVvDywt2mhpX5+qmhoeuCEH1Y115nhvaD96gu4y3gD7F6c/fh0Re63PQZRIl4x3cfruM8Bv1qMfPUF3GW/YNL7f0AVjHhHXAH8E9gAua2cfrTK8qRZ+BQzKzDrgv3nr/yiknuB/gF0yc28qf/ne2sX96WmuAO7JzHu7uiObiObj7fe7hjLzFGBH4Cng0++0HcNbz7IQqJ7lGlCUtVgnInoDWwOL29i2tfLFVE5f9G6+r8xcnJlvFOU/BkZv0FF1X5053hvaj56gW4x3Zr6emcuK5TuAPtU3NPQgnT7eEfENoD/wj+vZj56gW4z3JvT9hi76OyUz11A5nfqpdvbRuo19AaCvLr34sjfwPJWLJxsvlNyrWZ0vsu6FkTcWy3ux7sWXz1O58LLVNoGfs+4NC2cWy++r2t8ngAe7emx6wnhXtTmPdS+gP4J1L+h+uKvHpoeP99/y1g+cjwFebHzfk15d8PfJ54D7gS2a7cPvd+eO9ybx/e7sMS++vx8otg3ge8D32tpHm33v6sHztdG/jB8HnqFyt8u/FmUXAEcVy/2ohK65VC5S3bVq238ttpsDfKytNovyXYs25hZtbl6U/19gdvGlnQ7s0dXj0kPG+2wq10+sBl4CflyUB3B5Uf9xoL6rx6WHj/dZVd/vB4EDunpcesh4ry7KHi1e/+b3u0vGe5P5fnfmmFM50/n74jv8BPBTirtP29pHay8fjyVJklQiXvMmSZJUIoY3SZKkEjG8SZIklYjhTZIkqUQMb5IkSSVieJPUJSJi+4h4tHj9MSIWFsvLIuKKru5fZ4qIQRHxRLFcHxGXtlP/X5q9v7+W/ZPUvfhTIZK6XEScDyzLzO91dV9aEhG9863n+G707SJiEHBbZg7rYLvLMvPd69sfST2DM2+SupWIGBsRtxXL50fETyLi3oj4Q0R8MiK+GxGPR8RviodqExGjI+J3ETEjIqZGxPtaaHdSRFwZEQ0R8UxEHFmU94qIiyPikYiYFRGfr+rHvRExBXiyhfaWRcQlETE7Iu6MiP5F+d0R8e8R0QB8ubW+FeWPRcRjVH5hvaXjf3dEXFMc76yI+FREXARsUcxS/rSxL8WfURzLE8U2n65q8+6IuCkino6In0ZEbKzPTFLnMrxJ6u7eDxwCHAVcB0zPzOHACuCIIsBdBhybmaOBq4ELW2lrEJVH/hwBXBkR/YDTgNcycx9gH+DvI2JwUX8U8OXM3L2FtrYEGjJzL+B3wDeq1vXNzHrg0jb6dg3wpaw8ALw15xV9G56ZdcBdmXkOsCIzR2Tmic3qfxIYAewNfAS4uCrIjgT+ARhK5ekoB7axX0ndWO/2q0hSl/p1Zq6KiMepPDvwN0X541TC2BBgGPDfxWRSL+DlVtq6MTPXAs9GxPPAHsBHgbqIOLaoszWwG/AmledovtBKW2uBG4rl64BbqtY1lrfYt4jYBtgmM+8p6l0LfKyFfXyEyrMOAcjMJa30pdEHgeuz8uDrVyLid1QC6evFsSwAiIhHqYzdfe20J6kbMrxJ6u7eAMjMtRGxKt+6UHctlb/DApidmft3oK3mF/lmsf2XMnNq9YqIGAssX49+VrfduF2LfSvCW2d7o2p5Df79L5WWp00lld0coH9E7A8QEX0iYq9W6h4XEZtFxPupnDqcA0wFvlB1/dzuEbFlB/a7GdA4W/e/aHkWq8W+ZeZSYGlEfLCo1/z0Z6P/Zt3r4bYtFlc19reZe4FPF9fx9Qc+TOVB15J6EMObpFLLzDephKjvFBf/Pwoc0Er1F6mEmV8DZ2TmSuDHVG5I+J/i5zquomOzUsuBMcU2hwAXrGffTgEuL05htnbzwLeBbYsbEB4DDi7KJwKzGm9YqPILYBbwGHAX8M+Z+ccOHIukEvGnQiRtEiJiEpWf47hpI7Xnz3VI6hLOvEmSJJWIM2+SJEkl4sybJElSiRjeJEmSSsTwJkmSVCKGN0mSpBIxvEmSJJXI/wegMcfcMfYxRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
    "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
    "plt.legend()\n",
    "plt.title(\"F1-score versus time per prediction\")\n",
    "plt.xlabel(\"Time per prediction\")\n",
    "plt.ylabel(\"F1-Score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXXoYNZt4dsW"
   },
   "source": [
    "Elbette, bu noktaların her biri için ideal konum, grafiğin sol üst köşesinde olmaktır (tahmin başına düşük süre, yüksek F1 puanı).\n",
    "\n",
    "Bizim durumumuzda, tahmin ve performans başına süre için açık bir fark var. En iyi performans gösteren modelimiz, tahmin başına bir büyüklük sırası daha uzun sürüyor, ancak yalnızca birkaç F1 puanı artışıyla sonuçlanıyor.\n",
    "\n",
    "Bu tür bir fark, makine öğrenimi modellerini kendi uygulamalarınıza dahil ederken aklınızda bulundurmanız gereken bir şeydir."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "9. NLP'ye Giriş.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
